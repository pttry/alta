{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional extension\n",
    "\n",
    "ORANI-G model uses a top-down regional split, and requires regional shares as input.\n",
    "\n",
    "This notebook compiles estimates for:\n",
    "\n",
    "* Regional output shares (REGSHR1, R001)\n",
    "* Regional investment shares (REGSHR2, R002)\n",
    "* Regional consumption shares (REGSHR3, R003)\n",
    "* Regional export shares (REGSHR4, R004)\n",
    "* Regional government spending shares (REGSHR5, R005)\n",
    "* Regional inventory shares (REGSHR6, R006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic modules\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "\n",
    "# HARPY module by Centre of Policy Studies for writing data into Header Array (HAR) format.\n",
    "# Available at https://github.com/GEMPACKsoftware/HARPY\n",
    "from harpy.har_file import HarFileObj\n",
    "from harpy.header_array import HeaderArrayObj as HAO\n",
    "\n",
    "import dataGetterFunction as dgf\n",
    "import harWriterFunction as hwf\n",
    "import checkerFunctions as cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose base year for data:\n",
    "baseYear = 2014\n",
    "# Raw data folder:\n",
    "rawFolder = \"rawdata\"\n",
    "# Folder for output HAR-files:\n",
    "harFolder = \"hardata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf.aggHAR(harFolder, \"basedata64.har\", \"basedata30.har\", \"AGGSUP3.har\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output and employment by region query OK\n",
      "Households' transactions by region query OK\n"
     ]
    }
   ],
   "source": [
    "# Define regional data location:\n",
    "urlDict = {\n",
    "\"Output and employment by region\":    \"kan/altp/statfin_altp_pxt_008.px\",\n",
    "\"Households' transactions by region\": \"kan/altp/statfin_altp_pxt_016.px\"}\n",
    "\n",
    "# Get data:\n",
    "dgf.getData(urlDict, baseYear = baseYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WHOLE COUNTRY', 'Uusimaa', 'Varsinais-Suomi', 'Satakunta', 'Kanta-Häme', 'Pirkanmaa', 'Päijät-Häme', 'Kymenlaakso', 'South Karelia', 'Etelä-Savo', 'Pohjois-Savo', 'North Karelia', 'Central Finland', 'South Ostrobothnia', 'Ostrobothnia', 'Central Ostrobothnia', 'North Ostrobothnia', 'Kainuu', 'Lapland', 'Åland', 'Extra-regio territory']\n"
     ]
    }
   ],
   "source": [
    "# Check the available regions from regional accounts:\n",
    "print([x[\"valueTexts\"] for x in dgf.getParams(\"kan/altp/statfin_altp_pxt_008.px\", \"kunnat\") if x[\"code\"] == \"Alue\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose regions and rename if necessary:\n",
    "REGIONS ={\n",
    "\"Uusimaa\":        \"Uusimaa\", \n",
    "\"Varsinais-Suomi\":\"VarsinSuomi\", \n",
    "\"Satakunta\":      \"Satakunta\", \n",
    "\"Kanta-Häme\":     \"KantaHame\", \n",
    "\"Pirkanmaa\":      \"Pirkanmaa\", \n",
    "\"Päijät-Häme\":    \"PaijatHame\",    \n",
    "\"Kymenlaakso\":    \"Kymenlaakso\", \n",
    "\"South Karelia\":  \"EtelaKarjala\", \n",
    "\"Etelä-Savo\":     \"EtelaSavo\", \n",
    "\"Pohjois-Savo\":   \"PohjSavo\", \n",
    "\"North Karelia\":  \"PohjKarjala\", \n",
    "\"Central Finland\":\"KeskiSuomi\", \n",
    "\"South Ostrobothnia\":  \"EtelaPohjanm\",\n",
    "\"Ostrobothnia\":        \"Pohjanmaa\", \n",
    "\"Central Ostrobothnia\":\"KeskiPohjanm\", \n",
    "\"North Ostrobothnia\":  \"PohjPohjanm\",\n",
    "\"Kainuu\":  \"Kainuu\", \n",
    "\"Lapland\": \"Lappi\", \n",
    "\"Åland\":   \"Ahvenanmaa\"}\n",
    "\n",
    "REG = [r for r in REGIONS.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in regional data:\n",
    "regionalData = {k: pd.read_csv(rawFolder+\"/\"+str(k)+\"_Rawdata.csv\",\n",
    "                               # Use different encoding to display umlaut letters correctly:\n",
    "                               encoding=\"ISO-8859-1\", \n",
    "                               na_values =\".\") for k in urlDict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and rename:\n",
    "for k in regionalData:\n",
    "    regionalData[k].fillna(0, inplace = True)\n",
    "    regionalData[k] = regionalData[k][regionalData[k][\"Area\"].isin(list(REGIONS.keys()))]\n",
    "    \n",
    "    for col in regionalData[k]:\n",
    "        if col in [\"Industry\", \"Sector\", \"Transaction\"]:\n",
    "            # Get the code, drop the long name:\n",
    "            regionalData[k][col] = regionalData[k][col].apply(lambda x: x.split(\" \")[0]) \n",
    "        \n",
    "        if col == \"Industry\":\n",
    "            # Add the prefix \"I_\" for all industries:\n",
    "            regionalData[k][col] = regionalData[k][col].apply(lambda x: \"{}{}\".format(\"I_\", x))\n",
    "            # Drop redundant aggregates:\n",
    "            regionalData[k].drop(regionalData[k][regionalData[k].Industry.isin([\"I_0\"])].index, inplace=True)\n",
    "    # Rename:                    \n",
    "    regionalData[k].replace({**REGIONS, \n",
    "                             **{\"Current prices\":\"CP\", \"At previous year`s prices\": \"FP\"},\n",
    "                             **{\"I_681+68209+683\": \"I_68\", \"I_68201_68202\": \"I_68A\"}}, inplace = True)\n",
    "            \n",
    "    regionalData[k].reset_index(drop = True, inplace= True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regOutput = regionalData[\"Output and employment by region\"].copy()\n",
    "regHH = regionalData[\"Households' transactions by region\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regBaseData = HarFileObj.loadFromDisk(harFolder+\"/basedata30.har\")\n",
    "\n",
    "regInd = regBaseData.getHeaderArrayObj(\"IND\")[\"array\"].tolist()\n",
    "regCom = regBaseData.getHeaderArrayObj(\"COM\")[\"array\"].tolist()\n",
    "regSrc = regBaseData.getHeaderArrayObj(\"SRC\")[\"array\"].tolist()\n",
    "regMar = regBaseData.getHeaderArrayObj(\"MAR\")[\"array\"].tolist()\n",
    "\n",
    "regInd = [i.strip(' ') for i in regInd]\n",
    "regCom = [c.strip(' ') for c in regCom]\n",
    "regSrc = [s.strip(' ') for s in regSrc]\n",
    "regMar = [m.strip(' ') for m in regMar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that industries in the aggregated basedata match with the regional data:\n",
    "set(regOutput.Industry) == set(regInd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regional shares are derived from following data:\n",
    "\n",
    "* **R001 Regional output:** StatFin --> National accounts --> Regional account --> Output and employment, 30 industries --> P1R Output at basic prices\n",
    "* **R002 Regional investment:** StatFin --> National accounts --> Regional account --> Output and employment, 30 industries --> P51TOT Gross fixed capital formation\n",
    "* **R003 Regional consumption:** StatFin --> National accounts --> Regional account --> Households' transactions --> B6NT Disposable income, net\n",
    "* **R004 Regional export:** Customs --> International trade in goods by region\n",
    "* **R005 Regional government:** StatFin --> National accounts --> Regional account --> Households' transactions --> KVAKI Mean population\n",
    "* **R006 Regional inventories:** = Set according to R002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, collect levels data for all required entries:\n",
    "regLevels = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGOUTPUT contains:\n",
    "\n",
    "# P1R     Output at basic prices\n",
    "# P2K     Intermediate consumption\n",
    "# B1GPHT  Value added, gross at basic prices\n",
    "# D1K     Compensation of employees\n",
    "# E1_1H   Employment, persons\n",
    "# E11_1H  Employment, self-employed (persons)\n",
    "# E12_1H  Employees, persons\n",
    "# E2_T    Total hours worked (1,000 hours)\n",
    "# E21_T   Hours worked, self-employed (1,000 hours)\n",
    "# E22_T   Hours worked, employees (1,000 hours)\n",
    "# P51TOT  Gross fixed capital formation\n",
    "\n",
    "regInfos = {      # Dimensions:\n",
    "\"R001\": \"P1R\",    # (IND, REG)\n",
    "\"R002\": \"P51TOT\"} # (IND, REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in regInfos:\n",
    "    data = regOutput[(regOutput[\"Transaction\"] == regInfos[i]) & (regOutput[\"Sector\"] == \"S1\") & (regOutput[\"Data\"] == \"CP\")]\n",
    "    pivotData = data.pivot(index = \"Industry\", columns = \"Area\", values = str(baseYear))\n",
    "    regLevels[i] = pivotData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGHH contains:\n",
    "\n",
    "# B2NT:   Operating surplus, net\n",
    "# B3NT:   Mixed income, net\n",
    "# D11R_2: Wages and salaries (incl. employee stock options)\n",
    "# D12R:   Employers' social contributions\n",
    "# D4R_2:  Property income (including holding gains and losses)\n",
    "# D4K:    Property expenditure\n",
    "# B5NT1:  National income / balance of primary incomes, net\n",
    "# D62R:   Social benefits other than social transfers in kind, receivable\n",
    "# D7R:    Other current transfers, receivable\n",
    "# D5K:    Current taxes on income and wealth, etc., payable\n",
    "# D61K:   Social contributions, payable\n",
    "# D7K:    Other current transfers, payable\n",
    "# B6NT:   Disposable income, net\n",
    "# KVAKI:  Mean population (persons)\n",
    "\n",
    "regInfos2 = {      # Dimensions:\n",
    "\"R003\": \"B6NT\",    # (COM, REG)\n",
    "\"R005\": \"KVAKI\"}   # (COM, REG)\n",
    "\n",
    "# Initialize empty dataframes:\n",
    "for num in [\"R003\", \"R004\", \"R005\"]:\n",
    "    regLevels[num] = pd.DataFrame(0.0, columns=REG, index = regCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in regInfos2:\n",
    "    data = regHH[regHH[\"Transaction\"] == regInfos2[j]].set_index(\"Area\")[str(baseYear)]\n",
    "    for r in REG:\n",
    "        regLevels[j][r] = data.loc[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inventory shares are set equal to the investment shares. \n",
    "# However, the index is IND for investment, and COM for inventories, so swap them accordingly:\n",
    "regLevels[\"R006\"] = regLevels[\"R002\"].rename(index= dict(zip(regInd, regCom)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data from customs: (m€)\n",
    "regExports ={\n",
    "\"Uusimaa\":      19522, \n",
    "\"VarsinSuomi\":  3806, \n",
    "\"Satakunta\":    3852, \n",
    "\"KantaHame\":    1471, \n",
    "\"Pirkanmaa\":    4125, \n",
    "\"PaijatHame\":   1655,    \n",
    "\"Kymenlaakso\":  4886, \n",
    "\"EtelaKarjala\": 1309, \n",
    "\"EtelaSavo\":    399, \n",
    "\"PohjSavo\":     1093, \n",
    "\"PohjKarjala\":  804, \n",
    "\"KeskiSuomi\":   1904, \n",
    "\"EtelaPohjanm\": 594,\n",
    "\"Pohjanmaa\":    3266, \n",
    "\"KeskiPohjanm\": 1616, \n",
    "\"PohjPohjanm\":  1572,\n",
    "\"Kainuu\":       144, \n",
    "\"Lappi\":        3291, \n",
    "\"Ahvenanmaa\":   85}\n",
    "\n",
    "for r in regExports:\n",
    "    regLevels[\"R004\"][r] = regExports[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframes:\n",
    "for frame in regLevels:\n",
    "    regLevels[frame] = regLevels[frame][REG]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R001\n",
      "No negative values\n",
      "R002\n",
      "Negative values in [('I_16', 'Pohjanmaa', -2.2), ('I_17_18', 'VarsinSuomi', -0.3), ('I_17_18', 'EtelaSavo', -0.1), ('I_29_30', 'Satakunta', -8.3), ('I_31_33', 'PaijatHame', -0.9), ('I_45_47', 'KeskiPohjanm', -5.9)]\n",
      "R003\n",
      "No negative values\n",
      "R004\n",
      "No negative values\n",
      "R005\n",
      "No negative values\n",
      "R006\n",
      "Negative values in [('C_16', 'Pohjanmaa', -2.2), ('C_17_18', 'VarsinSuomi', -0.3), ('C_17_18', 'EtelaSavo', -0.1), ('C_29_30', 'Satakunta', -8.3), ('C_31_33', 'PaijatHame', -0.9), ('C_45_47', 'KeskiPohjanm', -5.9)]\n"
     ]
    }
   ],
   "source": [
    "# Check that negative values don't exist.\n",
    "# If they do, the next step will set them to zero. Then, re-run this block, and the next.\n",
    "for x in regLevels:\n",
    "    print(x)\n",
    "    cfs.check4negs(regLevels[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R002 I_16 Pohjanmaa was set to zero!\n",
      "R002 I_17_18 VarsinSuomi was set to zero!\n",
      "R002 I_17_18 EtelaSavo was set to zero!\n",
      "R002 I_29_30 Satakunta was set to zero!\n",
      "R002 I_31_33 PaijatHame was set to zero!\n",
      "R002 I_45_47 KeskiPohjanm was set to zero!\n",
      "R006 C_16 Pohjanmaa was set to zero!\n",
      "R006 C_17_18 VarsinSuomi was set to zero!\n",
      "R006 C_17_18 EtelaSavo was set to zero!\n",
      "R006 C_29_30 Satakunta was set to zero!\n",
      "R006 C_31_33 PaijatHame was set to zero!\n",
      "R006 C_45_47 KeskiPohjanm was set to zero!\n"
     ]
    }
   ],
   "source": [
    "# Set negative values for zero. Check that the values are small!!\n",
    "flag = True\n",
    "for x in regLevels:\n",
    "    for i in regLevels[x].index:\n",
    "        for c in regLevels[x].columns:\n",
    "            value = regLevels[x].loc[i][c]\n",
    "            if value < 0:\n",
    "                flag = False\n",
    "                regLevels[x].loc[i][c] = 0\n",
    "                print(x,i,c, \"was set to zero!\")\n",
    "if flag:\n",
    "    print(\"Ok! No negative values found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from levels to shares:\n",
    "regShares = {}\n",
    "for data in regLevels:\n",
    "    levelsData = regLevels[data]\n",
    "    rowSum = levelsData.sum(axis = 1)\n",
    "    sharesData = levelsData.div(rowSum, axis = 0)\n",
    "    regShares[data] = sharesData\n",
    "    # If the sumRow has entries with 0, it will cause division by zero and NAN values.\n",
    "    # If that occurs, replace them with a uniform value 1 / number of regions\n",
    "    for ix in rowSum.index:\n",
    "        if rowSum.loc[ix] == 0:\n",
    "            regShares[data].loc[ix] = 1/len(REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R001\n",
      "No nan values\n",
      "R002\n",
      "No nan values\n",
      "R003\n",
      "No nan values\n",
      "R004\n",
      "No nan values\n",
      "R005\n",
      "No nan values\n",
      "R006\n",
      "No nan values\n"
     ]
    }
   ],
   "source": [
    "# Check that NAN values don't exist:\n",
    "for x in regShares:\n",
    "    print(x)\n",
    "    cfs.check4nans(regShares[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other regional support data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional dimensions:\n",
    "allDims = {\n",
    "\"COM\": regCom,\n",
    "\"IND\": regInd,\n",
    "\"SRC\": regSrc,\n",
    "\"REG\": REG,\n",
    "\"MAR\": regMar,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional population:\n",
    "regPop = regHH[regHH[\"Transaction\"] == \"KVAKI\"].set_index(\"Area\")\n",
    "PO01 = regPop[str(baseYear)].to_frame(name = \"RPOP\")\n",
    "\n",
    "# Shortest distance from r to d:\n",
    "DIST = pd.read_excel(\"supplementaryData/regDistances.xlsx\")\n",
    "\n",
    "# Distance factor for gravity formula\n",
    "DFAC = pd.DataFrame(1.0, index = regCom, columns = [\"dom\", \"imp\"])\n",
    "DFAC.loc[[\"C_35_39\", \"C_41_43\",\"C_68\", \"C_68A\"]] = 2.0\n",
    "\n",
    "# Margin weighting\n",
    "MWGT = pd.DataFrame(1.0, index = REG, columns =allDims[\"MAR\"])\n",
    "\n",
    "# Distance related margins\n",
    "DMAR = [\"C_49_53\"]\n",
    "\n",
    "# Tendency to be locally sourced\n",
    "LMAR = pd.DataFrame(1.0, index = allDims[\"MAR\"], columns = [\"LOCMAR\"])\n",
    "LMAR.loc[\"C_45_47\"] = 3.0\n",
    "\n",
    "# Between-region Armington\n",
    "SGDD = pd.DataFrame(5.0, index = regCom, columns = [\"SIGMADOMOM\"])\n",
    "\n",
    "# Elasticity of substitution between regions of margin product\n",
    "SMAR = pd.DataFrame(0.2, index = allDims[\"MAR\"], columns = [\"SIGMAMAR\"])\n",
    "\n",
    "# Truly local commodities\n",
    "RLOC = [\"C_68\", \"C_68A\", \"C_85\", \"C_86_88\"]\n",
    "\n",
    "# Share of national imports, by port of entry\n",
    "MSHR = pd.DataFrame(1/len(REGIONS), index = regCom, columns = REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regional employment:\n",
    "regEmp = regOutput[(regOutput[\"Transaction\"] == \"E1_1H\") &\n",
    "                   (regOutput[\"Sector\"] == \"S1\") &\n",
    "                   (regOutput[\"Data\"] == \"CP\")].groupby([\"Area\"]).sum().reindex(REG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output data to HAR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regData={\n",
    "#coefficient name: (dataset, header name, long name, [list of dimensions])\n",
    "\n",
    "# Regional extension data\n",
    "\"REGSHR1\": (regShares[\"R001\"], \"R001\", \"Regional output shares\", [\"IND\", \"REG\"]),\n",
    "\"REGSHR2\": (regShares[\"R002\"], \"R002\", \"Regional investment shares\", [\"IND\", \"REG\"]),\n",
    "\"REGSHR3\": (regShares[\"R003\"], \"R003\", \"Regional consumption shares\", [\"COM\", \"REG\"]),\n",
    "\"REGSHR4\": (regShares[\"R004\"], \"R004\", \"Regional export shares\", [\"COM\", \"REG\"]),\n",
    "\"REGSHR5\": (regShares[\"R005\"], \"R005\", \"Regional government shares\", [\"COM\", \"REG\"]),\n",
    "\"REGSHR6\": (regShares[\"R006\"], \"R006\", \"Regional inventory shares\", [\"COM\", \"REG\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "regSupp = {   \n",
    "\"RPOP\":      (PO01, \"PO01\", \"Regional population\",[\"REG\"]),    \n",
    "\"DISTANCE\":  (DIST, \"DIST\", \"Shortest distance\",  [\"REG\", \"REG\"]),\n",
    "\"DISTFAC\":   (DFAC, \"DFAC\", \"Distance factor\",    [\"COM\", \"SRC\"]),    \n",
    "\"MWGT\":      (MWGT, \"MWGT\", \"Margin weighting\",   [\"REG\", \"MAR\"]), \n",
    "\"DMAR\":      DMAR,   # Set\n",
    "\"LMAR\":      (LMAR, \"LMAR\", \"Tendency to be locally sourced\", [\"MAR\"]),    \n",
    "\"SIGMADOMOM\":(SGDD, \"SGDD\", \"Between-region Armington\", [\"COM\"]),    \n",
    "\"SIGMAMAR\":  (SMAR, \"SMAR\", \"Elasticity of substitution between regions of margin production\",[\"MAR\"]),\n",
    "\"RLOC\":      RLOC,  # Set\n",
    "\"REGIMPSHR\": (MSHR, \"MSHR\", \"Regional import share\", [\"COM\", \"REG\"]),\n",
    "\"EMPLOY_R\":  (regEmp, \"EMPR\", \"Employment by region\", [\"REG\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dimensions as sets. Also include the regional data:\n",
    "output = {**allDims, **regData}\n",
    "hwf.data2har(output, allDims).writeToDisk(harFolder+\"/regExtension.har\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {**allDims, **regSupp}\n",
    "hwf.data2har(output, allDims).writeToDisk(harFolder+\"/REGSUPP.har\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
