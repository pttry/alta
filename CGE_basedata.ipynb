{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a core CGE model database for Finland from published data\n",
    "\n",
    "\n",
    "This iPython notebook builds a core CGE model database for Finland using published national accounts data. First, raw data are queried from the Statistics Finland API, cleaned and filtered. Next, the initial data balance and model compatibility are tested. The steps for creating the actual database are explained in detail in the paper \"Constructing a CGE Database Using GEMPACK for an African Country\" by Roos, Adams and van Heerden. This notebook simply replicates those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NATIONAL DATA (64 industries, 64 commodities)\n",
    "\n",
    "\n",
    "#### Import necessary Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Python packages (included in the Anaconda installation):\n",
    "\n",
    "import pandas as pd # Python data analysis library: https://pandas.pydata.org/\n",
    "import numpy  as np # Python scientific computing package: http://www.numpy.org/\n",
    "import os           # Python operating system interface (for managing files and folders via this notebook)\n",
    "import re           # Python regular expressions (Perl-style regular expression patterns). E.g. for matching string patterns.\n",
    "import pickle       # To save intermediate data as objects\n",
    "\n",
    "# HARPY module by Centre of Policy Studies. \n",
    "# Writes data from Python into Header Array (.har) format.\n",
    "# Available at https://github.com/GEMPACKsoftware/HARPY or using directly through pip: pip install by harpy3\n",
    "from harpy.har_file import HarFileObj\n",
    "from harpy.header_array import HeaderArrayObj as HAO\n",
    "\n",
    "\n",
    "# Other Python sequences in the working directory:\n",
    "import dataGetterFunction as dgf  # To search and query the Statistics Finland API.\n",
    "import harWriterFunction  as hwf  # A sequence that simplifies the output of large files.\n",
    "import checkerFunctions as cfs    # Simple functions to quickly check data consistency by comparing column and row sums.\n",
    "import mapperFunction as mf       # Function to map industries and commodities to an aggregate level.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose base year for data:\n",
    "baseYear = 2014\n",
    "# Raw data folder:\n",
    "rawFolder = \"rawdata\"\n",
    "# Folder for output HAR-files:\n",
    "harFolder = \"hardata\"\n",
    "os.makedirs(harFolder, exist_ok=True)\n",
    "# Location of bundle16 files from http://www.copsmodels.com/gpmark9.htm\n",
    "bundle16Folder = \"bundle16\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REMOVE OLD DATA?\n",
    "Set \"remove\" to eiher True or False. This removes old data versions from the current working directory, raw data directory and the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing was removed\n"
     ]
    }
   ],
   "source": [
    "remove = False\n",
    "\n",
    "flag = []\n",
    "# Flags are used throughout this notebook just to stay on track\n",
    "# what happens inside for-loops (or what doesn't happen).\n",
    "\n",
    "redundants = [\"csv\", \"log\", \"LOG\", \"gss\", \"gst\", \"bak\", \"har\", \"HAR\", \"inf\", \"min\", \"mnc\"]\n",
    "# All supplementary data is in .xlsx format, so don't remove those.\n",
    "\n",
    "def remover(file, folder = None):\n",
    "    if folder == None:\n",
    "        filename = file\n",
    "    else:\n",
    "        filename = folder+\"/\"+file\n",
    "    filetype = filename.split(\".\")[-1]\n",
    "    if filetype in redundants:\n",
    "        flag.append(filename)\n",
    "        os.unlink(filename)\n",
    "        print(\"Removed\", filename)\n",
    "    \n",
    "if remove:\n",
    "    for filename in os.listdir():\n",
    "        remover(filename)\n",
    "    for rawdata in os.listdir(rawFolder):\n",
    "        remover(rawdata, rawFolder)\n",
    "    for hardata in os.listdir(harFolder):\n",
    "        remover(hardata, harFolder)\n",
    "\n",
    "if not flag:\n",
    "    print(\"Nothing was removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data location in the StatFin API\n",
    "\n",
    "Specify data location as a dictionary. The dictionary key is a (user-specified) name\n",
    "for the data, and the key must be the actual px-web location. If errors occur, use the dgf.searchStatfin(\"...\") to check that the px-location is correct. Use, for instance, dgf.searchStatfin(\"supply table\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDict = {\n",
    "\"Supply table at basic prices\":          \"kan/pt/statfin_pt_pxt_001.px\",\n",
    "\"Use table at basic prices\":             \"kan/pt/statfin_pt_pxt_002.px\",\n",
    "\"Use table at purchasers prices\":        \"kan/pt/statfin_pt_pxt_003.px\",\n",
    "\"Imports use table at basic prices\":     \"kan/pt/statfin_pt_pxt_005.px\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supply table at basic prices query OK\n",
      "Use table at basic prices query OK\n",
      "Use table at purchasers prices query OK\n",
      "Imports use table at basic prices query OK\n"
     ]
    }
   ],
   "source": [
    "# Perform query. Raw data files (.csv) should appear in the rawdata directory.\n",
    "# If baseYear is not specified, this will query data for all available years.\n",
    "\n",
    "dgf.getData(urlDict, baseYear = baseYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data:\n",
    "ioData = {k: pd.read_csv(rawFolder+\"/\"+str(k)+\"_Rawdata.csv\",encoding=\"utf-8\",na_values =\".\") for k in urlDict.keys()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "The function below renames all industries and commodities in raw data files by replacing the long names with the representative classification codes. It also adds different prefixes for industries (\"I\") and commodities (\"C\"). For example \"01 Agriculture and hunting\" is shortened to \"I_01\", and \"10_12 Food products, beverages and tobacco\" becomes \"C_10_12\". Also, to avoid later errors in GEMPACK, all instances of \"/\" are replaced with an underscore.\n",
    "\n",
    "All industries and commodities are then collected to the lists IND and COM. They should be identical in size: 64 industries and 64 commodities. This might change in later data releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNrename(df, attribute, prefix):\n",
    "    \"\"\"\n",
    "    This function takes a DataFrame as input and cleans it from the long Statfin naming convention\n",
    "    \"number longname\" to the model convention \"PREFIX_number\".\n",
    "    E.g. \"01 Agriculture and hunting\" becomes \"I_01\" and \"17 Paper and paper products\" becomes \"C_17\".\n",
    "    \n",
    "    Inputs: DataFrame to be cleaned, attribute (column, index...) and a prefix (\"C_\" or \"I_\").\n",
    "    \"\"\"\n",
    "    for x in getattr(df, attribute):\n",
    "        dataCode = x.split(\" \")[0]\n",
    "        if \"/\" in dataCode:\n",
    "            dataCode = dataCode.replace(\"/\",\"_\")\n",
    "        if dataCode[0].isdigit():\n",
    "            newName = prefix + dataCode\n",
    "        else:\n",
    "            newName = dataCode\n",
    "        df.rename(**{attribute: {x:newName}}, inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data:\n",
    "for i in ioData:\n",
    "    # Take only current prices data if also other available \n",
    "    if \"Information\" in ioData[i].columns:\n",
    "        ioData[i] = ioData[i][ioData[i].Information == \"Current prices\"]\n",
    "        ioData[i].drop(\"Information\", axis = 1, inplace = True)\n",
    "    # Replace missing values with zeros:\n",
    "    ioData[i].fillna(0, inplace = True)\n",
    "    # Set the product column as index:\n",
    "    ioData[i].set_index(\"Product\", inplace = True)\n",
    "    # Drop redundant columns if they exist:\n",
    "    for redundant in [\"Year\", \"0 Industries total\"]:\n",
    "        if redundant in ioData[i].columns:\n",
    "            ioData[i].drop(redundant, axis = 1, inplace = True)\n",
    "    # Rename rows and columms using the splitNrename function above.\n",
    "    # Note: commodities (\"C_\") are listed in the index and industries (\"I_\") are listed in columns.\n",
    "    for attr, prefix in {\"index\": \"C_\", \"columns\": \"I_\"}.items():\n",
    "        splitNrename(ioData[i], attr, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store available industries and commodities as lists:\n",
    "IND = [ind for ind in ioData[\"Supply table at basic prices\"].columns if ind[0:2] == \"I_\"]\n",
    "COM = [com for com in ioData[\"Supply table at basic prices\"].index if com[0:2] == \"C_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Size is 64 x 64\n"
     ]
    }
   ],
   "source": [
    "# Check that the COM and IND dimensions are equal in length (original data is symmetrical):\n",
    "print(len(IND) == len(COM))\n",
    "print(\"Size is\", len(IND), \"x\", len(COM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define different types of user groups and supply sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "finUse = [   # Final users\n",
    "\"P51\",       # Gross fixed capital formation\n",
    "\"P52\",       # Changes in inventories\n",
    "\"P6K\",       # Exports\n",
    "\"P3_S13\",    # Government consumption\n",
    "\"P3_S14\",    # Household consumption\n",
    "\"P3_S15\"]    # Consumption by non-profit organisations\n",
    "\n",
    "valAdd = [   # Value add components\n",
    "\"D1\",        # Compensation of employees\n",
    "\"D29MD39\",   # Other net taxes on production\n",
    "\"P51C\",      # Consumption of fixed capital\n",
    "\"B13NT\"]     # Operating surplus + mixed income \n",
    "    \n",
    "supComp = [   # Supply components\n",
    "\"P7R_CIF\",   # Imports at c.i.f. prices\n",
    "\"TRTP_MARG\", # Trade and transport margins\n",
    "\"D21N\"]      # Taxes less subsidies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unwanted data entries and store results in a new dictionary called cleanData:\n",
    "cleanData = {}\n",
    "cleanData[\"usetable_PP\"] = ioData[\"Use table at purchasers prices\"].reindex(COM + valAdd)[IND + finUse]\n",
    "cleanData[\"usetable_BP\"] = ioData[\"Use table at basic prices\"].reindex(COM + valAdd)[IND + finUse]\n",
    "cleanData[\"supplytable_BP\"]  = ioData[\"Supply table at basic prices\"].reindex(COM)[IND+supComp]\n",
    "cleanData[\"usetable_Imp_BP\"] = ioData[\"Imports use table at basic prices\"].reindex(COM + valAdd)[IND + finUse].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the original raw data is balanced and consistent with the CGE model:\n",
    "\n",
    "#### Check for negative values in original data\n",
    "\n",
    "Negative values are only allowed in changes in inventories. Check that no negative values exist elsewhere in the original data. Possible negative values are set to zero and redistributed into changes in inventories (user code \"P52\"). Re-run this block to check that no negative values remain. Also check that if negative values exist, they are small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP P3_S13 C_62_63 : value -2.0  assigned to changes in inventories!\n",
      "BP P3_S13 C_62_63 : value -2.0  assigned to changes in inventories!\n",
      "PP P3_S13 C_68 : value -11.0  assigned to changes in inventories!\n",
      "BP P3_S13 C_68 : value -11.0  assigned to changes in inventories!\n",
      "PP P3_S13 C_69_70 : value -3.0  assigned to changes in inventories!\n",
      "BP P3_S13 C_69_70 : value -3.0  assigned to changes in inventories!\n",
      "PP P3_S13 C_96 : value -6.0  assigned to changes in inventories!\n",
      "BP P3_S13 C_96 : value -6.0  assigned to changes in inventories!\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "for commodity in COM:\n",
    "    for user in IND + finUse:\n",
    "        for priceType in [\"PP\", \"BP\"]: # Purchaser price, basic price\n",
    "            if user != \"P52\": # Negative values are allowed in inventory changes, so exclude those\n",
    "                dataLocation = cleanData[\"usetable_\"+priceType].loc[commodity]\n",
    "                if dataLocation[user] < 0:   \n",
    "                    flag = False\n",
    "                    negValue = dataLocation[user]                     \n",
    "                    dataLocation[\"P52\"] += negValue                   \n",
    "                    dataLocation[user] = 0                           \n",
    "                    print(priceType, user, commodity,\": value\", negValue, \" assigned to changes in inventories!\")\n",
    "                    \n",
    "if flag:\n",
    "    print(\"OK! No negative values encountered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that current price GDP from income side equals GDP from expenditure side (well enough):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDPexp is 205473.99700000006 \n",
      "GDPinc is 205474.001 \n",
      "Difference is -0.003999999928055331\n"
     ]
    }
   ],
   "source": [
    "GDPexp = cleanData[\"usetable_PP\"].loc[COM][finUse].sum().sum() - cleanData[\"supplytable_BP\"][\"P7R_CIF\"].sum()\n",
    "GDPinc = cleanData[\"usetable_PP\"].loc[valAdd].sum().sum() + cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"].sum()\n",
    "\n",
    "print(\"GDPexp is\", GDPexp,\"\\nGDPinc is\", GDPinc, \"\\nDifference is\", GDPexp-GDPinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that aggregate supply (BP) equals aggregate demand (PP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow a small deviation:\n",
    "allowDifference = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "cfs.checkColSums(cleanData[\"supplytable_BP\"].loc[COM], cleanData[\"usetable_PP\"].loc[COM], allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that national accounts identities hold in original data:\n",
    "\n",
    "PP = BP - net taxes - margins from producer side + margins from user side\n",
    "\n",
    "Basic flows = BP - margins = PP - taxes - margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check1: Purchaser's price - taxes = basic price (differences in margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Margins inferred from data:\n",
    "margtest=(cleanData[\"usetable_PP\"].loc[COM] -\\\n",
    "          cleanData[\"usetable_BP\"].loc[COM]).sum(axis=1)-cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"]\n",
    "# Actual margins data\n",
    "realmarg = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "\n",
    "cfs.checkCols(margtest, realmarg, allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check2: total sum of differences is near zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs((margtest-realmarg).sum()) < allowDifference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check3: domestic use equals domestic supply (MAKE_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check that supply and use by commodity is balanced:\n",
    "domUse = cleanData[\"usetable_BP\"].loc[COM].sum(axis=1) - cleanData[\"supplytable_BP\"][\"P7R_CIF\"]\n",
    "MAKE_I = cleanData[\"supplytable_BP\"][IND].sum(axis=1)\n",
    "\n",
    "cfs.checkCols(domUse, MAKE_I, allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check4: Basic price - basic flows - margins_C = 0, where \n",
    "\n",
    "basic flows =  PUR - tax - margins_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define total margins used per commodity\n",
    "MAR_M = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "for i in MAR_M.index:\n",
    "    if MAR_M.loc[i] < 0:\n",
    "        MAR_M.loc[i] = 0      \n",
    "# And total margins produced per margin commodity\n",
    "MAR_C = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "for c in MAR_C.index:\n",
    "    if MAR_C.loc[c] >= 0:\n",
    "        MAR_C.loc[c] = 0\n",
    "    else:\n",
    "        MAR_C.loc[c] = MAR_C.loc[c] * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "#Total flows:\n",
    "flows_U = cleanData[\"usetable_PP\"].loc[COM].sum(axis=1) - cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"] - MAR_M\n",
    "\n",
    "# Check:\n",
    "check4 = cleanData[\"usetable_BP\"].loc[COM].sum(axis=1) - flows_U - MAR_C\n",
    "cfs.checkCols(check4, pd.Series(0.0, index = COM), allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-profit consumption P3_S15 is aggregated to household consumption P3_S14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cleanData:\n",
    "    if \"P3_S15\" in cleanData[i]:\n",
    "        cleanData[i][\"P3_S14\"] += cleanData[i][\"P3_S15\"]\n",
    "        cleanData[i].drop(\"P3_S15\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor payments\n",
    "\n",
    "### V1LAB (Labour compensation)\n",
    "\n",
    "* From Use Table at purchaser's prices, select all industries and D1 (Compensation of employees). \n",
    "* Split D1 using occupational shares from the public Mitenna database by The Ministry of Education (see /supplementaryData/Mitenna-info.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw occupational data from MITENNA supplementary file:\n",
    "OCC_levels = pd.read_excel(\"supplementaryData/MITENNA_\"+str(baseYear)+\".xlsx\", skiprows = 1, index_col = 0)\n",
    "OCC_levels.fillna(0, inplace=True)\n",
    "# Drop redundant columns:\n",
    "OCC_levels.drop([\"Missing data\", \"Grand total\"], axis = 1, inplace = True)\n",
    "# Drop redundant rows:\n",
    "OCC_levels.drop([\"00000 Industry unknown\", \n",
    "                 \"Grand total\",\n",
    "                 \"99000 Activities of extraterritorial organisations and bodies\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped N  Administrative and support service activities with a total employment of 5.0 persons.\n",
      "Dropped R  Arts, entertainment and recreation with a total employment of 1.0 persons.\n"
     ]
    }
   ],
   "source": [
    "# Clean up the index names and column names.\n",
    "# For occupations: \"02.3 Metal workers\" becomes \"O_02_3\"\n",
    "# For industries:  \"01410 Raising of dairy cattle\" becomes \"I_01410, etc.\n",
    "\n",
    "for occupation in OCC_levels:\n",
    "    newName = \"O_\"+occupation.split(\" \")[0].replace(\".\",\"_\")\n",
    "    OCC_levels.rename(columns = {occupation:newName}, inplace = True)\n",
    "for industry in OCC_levels.index:\n",
    "    # The Mitenna data might contain industry aggregates, such as \"R Arts, entertainment and recreation\", \n",
    "    # that do not directly match with the input-output industry numbering convention. The next step removes\n",
    "    # all aggregate industry rows (those that start with a letter). Check that the total employment in \n",
    "    # these sectors is small enough to not cause any harm. \n",
    "    if re.search('[a-zA-Z]', industry[0]): \n",
    "        print(\"Dropped\", industry,\"with a total employment of\", OCC_levels.loc[industry].sum(), \"persons.\")  \n",
    "        OCC_levels.drop(industry, inplace = True)\n",
    "             \n",
    "    newName = \"I_\"+industry.split(\" \")[0]\n",
    "    OCC_levels.rename(index = {industry:newName}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the +850 Mitenna industries to a single list:\n",
    "mitennaIndustries = OCC_levels.index.tolist()\n",
    "# And create a mapping from Mitenna to Statfin input-output industry classification:\n",
    "mitennaIndMapper = mf.mapperFunction(mitennaIndustries, IND, exceptions={\"I_68A\":[\"I_68201\", \"I_68202\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the occupational data using the mappings specified above:\n",
    "OCC_levels[\"MAPPING\"] = pd.Series(mitennaIndMapper)\n",
    "OCC_levels_agg = OCC_levels.groupby([\"MAPPING\"], sort = False).sum()\n",
    "\n",
    "# Calculate industry specific occupation shares:\n",
    "OCCshares = OCC_levels_agg.divide(OCC_levels_agg.sum(axis=1), axis = \"index\").fillna(0)\n",
    "\n",
    "# Store the occupations dimension OCC to a list:\n",
    "OCC = OCC_levels_agg.columns.tolist()\n",
    "\n",
    "# And check that the number of workers in each occupation remains unchanged after aggregation:\n",
    "cfs.checkCols(OCC_levels_agg.sum(), OCC_levels[OCC].sum(), allowDifference = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Split the original labour compensation data:\n",
    "V1LAB_O = cleanData[\"usetable_BP\"].loc[\"D1\"][IND]\n",
    "V1LAB   = OCCshares.multiply(V1LAB_O, axis = \"index\")\n",
    "\n",
    "# Last, check that column sums still match the original data:\n",
    "cfs.checkCols(V1LAB.sum(axis=1), V1LAB_O, allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1CAP (Capital rentals)\n",
    "V1CAP is the industry-specific gross operating surplus (GOS). It is calculated for each industry by summing the net operating surplus (B13NT) and capital depriciation (P51C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values\n"
     ]
    }
   ],
   "source": [
    "V1CAP = cleanData[\"usetable_BP\"].loc[[\"P51C\", \"B13NT\"]].sum()\n",
    "V1CAP = V1CAP[IND].to_frame(\"V1CAP\")\n",
    "\n",
    "# Negative V1CAP implies negative profits. The model doesn't allow for negative profits, \n",
    "# so check that all values for V1CAP are non-negative.\n",
    "cfs.check4negs(V1CAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1LND (Land rentals)\n",
    "\n",
    "Next, the land rentals (V1LND) are separated for the land using sectors (agriculture, forestry, and mining) from V1CAP using the following shares:\n",
    "\n",
    "* Agriculture: 15.0% $^{1}$ \n",
    "* Forestry: 66% $^{2}$ \n",
    "* Mining and quarrying: 7.7% $^{2}$ \n",
    "\n",
    "\n",
    "1. Land value / total farm assets. Source:  Statfin >> Agriculture, Forestry and Fishery >> Statistics on the finances of agricultural and forestry enterprises (35/41, Year 2014, Entire country)\n",
    "\n",
    "2. The share of land improvements / total assets. Source:  Statfin >> National Accounts >> Annual national accounts >> 017 -- Gross capital, Net capital, consumption and retirements of fixed capital 1975-2016 (N1123/TOT, Gross stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize V1LND as a zero vector:\n",
    "V1LND = pd.DataFrame(0.0, index=IND, columns=[\"V1LND\"])\n",
    "\n",
    "# Specify lists of land-using industries:\n",
    "agrInd = [\"I_01\"]          # Agriculture\n",
    "forInd = [\"I_02\", \"I_03\"]  # Forest industry\n",
    "minInd = [\"I_05_09\"]       # Mining\n",
    "# Add construction industry?\n",
    "\n",
    "V1LND.loc[agrInd] = V1CAP.loc[agrInd].multiply(0.150)\n",
    "V1LND.loc[forInd] = V1CAP.loc[forInd].multiply(0.66)\n",
    "V1LND.loc[minInd] = V1CAP.loc[minInd].multiply(0.077)\n",
    "\n",
    "# Last, to avoid double counting, subtract V1LND from V1CAP\n",
    "V1CAP[\"V1CAP\"] -= V1LND[\"V1LND\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store user-specific purchaser's price values V1PUR-V6PUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "userNames = {\n",
    "\"V1\": IND,          # Industry\n",
    "\"V2\": [\"P51\"],      # Investment\n",
    "\"V3\": [\"P3_S14\"],   # Households\n",
    "\"V4\": [\"P6K\"],      # Export\n",
    "\"V5\": [\"P3_S13\"],   # Government\n",
    "\"V6\": [\"P52\"]}      # Inventories\n",
    "\n",
    "# A single list containing all users:\n",
    "userList = [item for sublist in userNames.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "VPUR_S = {} # Purchaser's price values summed over source dimension S (domestic/imported)\n",
    "for i in userNames:\n",
    "    VPUR_S[i+\"PUR\"] = cleanData[\"usetable_PP\"].loc[COM][userNames[i]]\n",
    "VPUR_US = cleanData[\"usetable_PP\"].loc[COM].sum(axis=1) # VPUR summed over dimensions source S and user U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE matrix (Multi-product matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matrix is simply extracted from the basic price supply table:\n",
    "MAKE = cleanData[\"supplytable_BP\"].loc[COM][IND].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1PTX (Production tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From use table, read D29MD39 Other net taxes on production:\n",
    "V1PTX = pd.DataFrame(cleanData[\"usetable_BP\"].loc[\"D29MD39\"][IND].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V0TAR (Tariff revenue)\n",
    "\n",
    "For import tariffs, only the total annual collected amount is available. It must be split between different commodities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Total tariff revenue is:\n",
    "V0TAR_tot = 163.090 # m€\n",
    "# Source: Finnish customs database at uljas.tulli.fi\n",
    "# State revenue debited by Finnish Customs from 2001, indicator D.1.1. (customs duties)\n",
    "\n",
    "# Total commodity specific imports are:\n",
    "impByCom = cleanData[\"supplytable_BP\"][\"P7R_CIF\"].copy()\n",
    "\n",
    "\n",
    "# Tariff data is only collected from goods classified in the Combined Nomenclature (CN).\n",
    "# Thus, set everything beyond C_32 to zero:\n",
    "for commodity in COM:\n",
    "    if int(commodity[2:4]) >= 33:\n",
    "        impByCom[commodity] = 0\n",
    "        \n",
    "# Imports are at C.I.F prices, so we can calculate the tariff share as:\n",
    "tariffShare = V0TAR_tot / impByCom.sum()\n",
    "\n",
    "# Store the values to a DataFrame \"V0TAR\":\n",
    "V0TAR = (impByCom * tariffShare).to_frame(name=\"V0TAR\")\n",
    "\n",
    "# Check that totals still match:\n",
    "cfs.checkNums(V0TAR.sum(), V0TAR_tot, allowDifference = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1OCT (Other cost ticket)\n",
    "\n",
    "For now, the other cost ticket is set to zero vector. In later stages, it can be used to handle e.g. pure profits and other miscellanious production costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1OCT = pd.DataFrame(0.0, index = IND, columns = [\"V1OCT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import shares\n",
    "\n",
    "Commodity-specific import shares are calculated as:\n",
    "\n",
    "$IMPSHR(c) =   \\frac{V0IMP(c)}{\\sum{users} VPUR(c,u)}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total imports per commodity:\n",
    "V0IMP = cleanData[\"supplytable_BP\"].loc[COM][\"P7R_CIF\"]\n",
    "# Commodity-specific import share:\n",
    "IMP_SHR = (V0IMP/VPUR_US).fillna(0)\n",
    "# Import share applied to all users:\n",
    "importMatrix = cleanData[\"usetable_PP\"].loc[COM].multiply(IMP_SHR, axis = \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create margin matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read margins data:\n",
    "MARGIN = cleanData[\"supplytable_BP\"][\"TRTP_MARG\"].copy()\n",
    "# Margin commodities are those with negative values in national accounting:\n",
    "MARGINCOMS = MARGIN[MARGIN<0]\n",
    "MARGIN[MARGIN<0] = 0 \n",
    "\n",
    "# Check that the total use and supply of margin commodities is in balance\n",
    "MARGIN.sum() + MARGINCOMS.sum() < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the margins dimension as a list:\n",
    "MAR = MARGINCOMS.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inventories are excluded from margin use\n",
    "marginUsers = [y for x in [v for k,v in userNames.items() if k != \"V6\"] for y in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The margin-use-ratios for each commodity are calculated as:\n",
    "\n",
    "$MARUSERATIO(c) =   \\frac{MARGIN(c)}{\\sum{user}\\sum{source} VPUR(u,s,c)}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAR_USERATIO = (MARGIN / cleanData[\"usetable_PP\"].loc[COM][marginUsers].sum(axis=1)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, calculate aggregate margin matrices for each user, summed over margin commodity M and source S:\n",
    "MARGIN_DICT1 = {}\n",
    "for i in VPUR_S:\n",
    "    if \"V6PUR\" not in i:\n",
    "        dataName = i\n",
    "        keyName = i[0:2]+\"MAR_S_M\"\n",
    "        MARGIN_DICT1[keyName] = VPUR_S[i].multiply(MAR_USERATIO, axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check balance\n",
    "marTotal1 = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for i in MARGIN_DICT1:\n",
    "    if \"V1\" in i:\n",
    "        marTotal1[\"TOTAL\"] += MARGIN_DICT1[i].sum(axis = 1)\n",
    "    else:\n",
    "        marTotal1[\"TOTAL\"] += MARGIN_DICT1[i].iloc[:,0]\n",
    "\n",
    "cfs.checkCols(marTotal1[\"TOTAL\"], MARGIN, allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the aggregate margins are split between different margin commodities:\n",
    "\n",
    "$ MARSHR(m) = \\frac{MARGIN(m)}{\\sum MARGINS(m)}   $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGINS = pd.DataFrame(abs(MARGINCOMS))\n",
    "MARGINS[\"MARSHR\"] = MARGINS[\"TRTP_MARG\"] / float(MARGINS.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN_DICT2 = {}\n",
    "for i in MARGIN_DICT1:\n",
    "    dummyFrame  = pd.DataFrame(0.0, index = COM, columns = MARGINS.index)\n",
    "    for j in MARGINS.index:       \n",
    "        if \"V1MAR\" in i:\n",
    "            keyName = i[0:-2]+\"_\"+j\n",
    "            MARGIN_DICT2[keyName] = MARGIN_DICT1[i].multiply(MARGINS[\"MARSHR\"].loc[j])\n",
    "        else:\n",
    "            dummyFrame[j] = MARGIN_DICT1[i] * MARGINS[\"MARSHR\"].loc[j]\n",
    "            MARGIN_DICT2[i[0:-2]] = dummyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# CHECK THAT TOTAL MARGINS EQUAL THE VALUE FROM STATFIN DATABASE\n",
    "marTotal2 = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for i in MARGIN_DICT2:\n",
    "    if \"V1\" in i:\n",
    "        marTotal2[\"TOTAL\"] += MARGIN_DICT2[i].sum(axis = 1)\n",
    "    else:\n",
    "        marTotal2[\"TOTAL\"] += MARGIN_DICT2[i].sum(axis = 1)\n",
    "        \n",
    "marTotal2[\"StatFin\"] = MARGIN\n",
    "cfs.checkCols(marTotal2[\"TOTAL\"], marTotal2[\"StatFin\"], allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors\n"
     ]
    }
   ],
   "source": [
    "# Check that the margin use is correctly distributed between different margin commodities C45- C52\n",
    "marComsDict = {}\n",
    "for k in MARGINCOMS.index:\n",
    "    marComsDict[k] = 0\n",
    "    \n",
    "for i in MARGINCOMS.index:\n",
    "    for j in MARGIN_DICT2:\n",
    "        if \"V1MAR\" in j:\n",
    "            if i in j:\n",
    "                marComsDict[i] += MARGIN_DICT2[j].sum().sum()\n",
    "        else:\n",
    "            marComsDict[i] += MARGIN_DICT2[j][i].sum()\n",
    "\n",
    "errorList = []\n",
    "for com in MARGINCOMS.index:\n",
    "    diff = MARGINCOMS[com] + marComsDict[com]\n",
    "    if abs(diff) > 0.001:\n",
    "        print(\"ERROR IN\", com, \"BY\", diff)\n",
    "        errorList.append([com, diff])\n",
    "if not errorList:\n",
    "    print(\"No errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, split the margins between domestic and imported sources.\n",
    "MARGIN_DICT3 = {}\n",
    "for i in MARGIN_DICT2:\n",
    "    if \"V4\" not in i:\n",
    "        user = i[0:2]\n",
    "        multiplierImp = IMP_SHR\n",
    "        multiplierDom = 1- multiplierImp\n",
    "        newName = i.replace(\"_S\",\"\")\n",
    "\n",
    "        impData = MARGIN_DICT2[i].multiply(multiplierImp, axis = \"index\")\n",
    "        domData = MARGIN_DICT2[i].multiply(multiplierDom, axis = \"index\")\n",
    "\n",
    "        MARGIN_DICT3[newName+\"_imp\"] = impData\n",
    "        MARGIN_DICT3[newName+\"_dom\"] = domData\n",
    "    else:\n",
    "        newName = i.replace(\"_S\",\"\")\n",
    "        MARGIN_DICT3[newName] = MARGIN_DICT2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check margin totals: \n",
    "mar1chk =pd.Series(0.0, index =COM)\n",
    "for k in MARGINCOMS.index:\n",
    "    for s in [\"_dom\", \"_imp\"]:        \n",
    "        mar1chk += MARGIN_DICT3[\"V1MAR_\"+k+s].sum(axis=1)\n",
    "\n",
    "mar2chk =\\\n",
    "MARGIN_DICT3[\"V2MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V2MAR_dom\"].sum(axis=1)\n",
    "\n",
    "mar3chk =\\\n",
    "MARGIN_DICT3[\"V3MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V3MAR_dom\"].sum(axis=1)\n",
    "\n",
    "mar4chk=\\\n",
    "MARGIN_DICT3[\"V4MAR\"].sum(axis=1)\n",
    "\n",
    "mar5chk =\\\n",
    "MARGIN_DICT3[\"V5MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V5MAR_dom\"].sum(axis=1)\n",
    "\n",
    "summa = sum([mar1chk,mar2chk,mar3chk,mar4chk,mar5chk])\n",
    "cfs.checkCols(summa, MARGIN, allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These aggregate matrixes are used for quick balance checking later on:\n",
    "V1MAR_C = pd.DataFrame(0.0, index = COM, columns = IND)\n",
    "V2MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V3MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V4MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V5MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "\n",
    "for i in MARGIN_DICT3:\n",
    "    if \"V1MAR\" in i:\n",
    "        data = MARGIN_DICT3[i].sum()     \n",
    "        if \"dom\" in i:\n",
    "            marCom = i[6:].replace(\"_dom\", \"\")\n",
    "        if \"imp\" in i:\n",
    "            marCom = i[6:].replace(\"_imp\", \"\")        \n",
    "        V1MAR_C.loc[marCom] += data\n",
    "  \n",
    "    if \"V2MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V2MAR_C.loc[k] += data.loc[k]\n",
    "\n",
    "\n",
    "    if \"V3MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V3MAR_C.loc[k] += data.loc[k]\n",
    "            \n",
    "    if \"V4MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V4MAR_C.loc[k] += data.loc[k]\n",
    "            \n",
    "    if \"V5MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V5MAR_C.loc[k] += data.loc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check that margin use matches the supply of margin commodities:\n",
    "cfs.checkNums(V1MAR_C.sum().sum() +\\\n",
    "V2MAR_C.sum() +\\\n",
    "V3MAR_C.sum() +\\\n",
    "V4MAR_C.sum() +\\\n",
    "V5MAR_C.sum(), abs(MARGINCOMS.sum()), allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "VMAR_M={}\n",
    "for user in range(1,6):\n",
    "    VMAR_M[\"V\"+str(user)] = MARGIN_DICT1[\"V\"+str(user)+\"MAR_S_M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect tax matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXBYCOM  = pd.DataFrame(cleanData[\"supplytable_BP\"][\"D21N\"].copy())\n",
    "\n",
    "# Following Roos et al. (2015), it is supposed that households pay most of the tax burden.\n",
    "# A tax weight factor is therefore assigned, giving households a weight factor of 3, and all other\n",
    "# users a weight factor of 1\n",
    "\n",
    "TAXFAC = pd.DataFrame(1.0, index = userList, columns = [\"TAXFAC\"]).sort_index()\n",
    "TAXFAC.loc[\"P3_S14\"] = 3.0\n",
    "WTOT =   cleanData[\"usetable_PP\"].loc[COM].T.multiply(TAXFAC[\"TAXFAC\"], axis=\"index\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxMatrix = pd.DataFrame(0.0, index = COM, columns = userList)\n",
    "for i in taxMatrix.index:\n",
    "    taxMatrix.loc[i] = TAXFAC[\"TAXFAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAX = taxMatrix.multiply(TAXBYCOM[\"D21N\"], axis = \"index\")\n",
    "VTAX=(cleanData[\"usetable_PP\"].loc[COM][userList]*TAX).divide(WTOT, axis = \"index\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxDict = {}\n",
    "taxDict[\"V1TAX_S\"] = VTAX[IND]\n",
    "taxDict[\"V2TAX_S\"] = VTAX[\"P51\"]\n",
    "taxDict[\"V3TAX_S\"] = VTAX[\"P3_S14\"]\n",
    "taxDict[\"V4TAX_S\"] = VTAX[\"P6K\"]\n",
    "taxDict[\"V5TAX_S\"] = VTAX[\"P3_S13\"]\n",
    "taxDict[\"V6TAX_S\"] = VTAX[\"P52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check totals:\n",
    "taxTotal = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for user in taxDict:\n",
    "    if user == \"V1TAX_S\":\n",
    "        taxTotal[\"TOTAL\"] += taxDict[user].sum(axis=1)\n",
    "    else:\n",
    "        taxTotal[\"TOTAL\"] += taxDict[user]\n",
    "cfs.checkCols(TAXBYCOM, taxTotal, allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split taxes between domestic and imported:\n",
    "taxDict2 = {}\n",
    "for user in taxDict:\n",
    "    for source in [\"dom\", \"imp\"]:\n",
    "        keyName = user[0:5]+source\n",
    "        origData = taxDict[user]\n",
    "        if source == \"dom\":\n",
    "            newData = origData.multiply(1-IMP_SHR, axis = \"index\")\n",
    "        else:\n",
    "            newData = origData.multiply(IMP_SHR, axis = \"index\")\n",
    "        taxDict2[keyName] = newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create matrices for basic flows\n",
    "\n",
    "Note: The model basic flows (V*BAS) are NOT the same as Statistics Finland basic price (BP) values. Importantly, the commodity-specific margin use must be deducted from the BP values to get the corresponding BAS entry:\n",
    "\n",
    "$BAS_{(u,c,dom)} = \\sum_{s \\in SRC}VPUR_{(u,c,s)} - BAS_{(u,c,imp)} - \\sum_{s \\in SRC} \\sum_{m \\in MAR} MAR_{(u,c,s,m)} -  \\sum_{s \\in SRC} TAX_{(u,c,s)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1BASimp = importMatrix[IND]\n",
    "V2BASimp = importMatrix[\"P51\"]\n",
    "V3BASimp = importMatrix[\"P3_S14\"]\n",
    "V4BASimp = importMatrix[\"P6K\"]\n",
    "V5BASimp = importMatrix[\"P3_S13\"]\n",
    "V6BASimp = importMatrix[\"P52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1BASdom = cleanData[\"usetable_PP\"].loc[COM][IND]      - V1BASimp - VMAR_M[\"V1\"] - taxDict[\"V1TAX_S\"]\n",
    "V2BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P51\"]    - V2BASimp - VMAR_M[\"V2\"].iloc[:,0] - taxDict[\"V2TAX_S\"]\n",
    "V3BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P3_S14\"] - V3BASimp - VMAR_M[\"V3\"].iloc[:,0] - taxDict[\"V3TAX_S\"]\n",
    "V4BAS    = cleanData[\"usetable_PP\"].loc[COM][\"P6K\"]    - V4BASimp - VMAR_M[\"V4\"].iloc[:,0] - taxDict[\"V4TAX_S\"]\n",
    "V5BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P3_S13\"] - V5BASimp - VMAR_M[\"V5\"].iloc[:,0] - taxDict[\"V5TAX_S\"]\n",
    "V6BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P52\"]    - V6BASimp - taxDict[\"V6TAX_S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic flows for V3-V6 have only two dimensions (commodity and source) so they can be compiled to single dataframes:\n",
    "V3BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "V4BAS = V4BAS.to_frame(name = \"V4BAS\")\n",
    "V5BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "V6BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "\n",
    "V3BAS[\"DOM\"] = V3BASdom\n",
    "V3BAS[\"IMP\"] = V3BASimp\n",
    "\n",
    "V5BAS[\"DOM\"] = V5BASdom\n",
    "V5BAS[\"IMP\"] = V5BASimp\n",
    "\n",
    "V6BAS[\"DOM\"] = V6BASdom\n",
    "V6BAS[\"IMP\"] = V6BASimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values\n",
      "No nan values\n",
      "No negative values\n",
      "No nan values\n",
      "No negative values\n",
      "No nan values\n",
      "No negative values\n",
      "No nan values\n",
      "No negative values\n",
      "No nan values\n"
     ]
    }
   ],
   "source": [
    "# Check that no negative values or nan values have emerged:\n",
    "for i in [V1BASdom, pd.DataFrame(V2BASdom), V3BAS, V4BAS, V5BAS]:\n",
    "    cfs.check4negs(i)\n",
    "    cfs.check4nans(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split investments between industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, industry dimension is added to V2PUR.\n",
    "Industry-specific capital rental share is used as a starting point:\n",
    "\n",
    "IND_SHR(i) = $\\frac{V1CAP(i)}{\\sum V1CAP(i)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_SHR = V1CAP/V1CAP.sum()\n",
    "\n",
    "# Initialize an empty matrix in IND * COM dimension\n",
    "indShareMatrix = pd.DataFrame(0.0, index = COM, columns = IND)\n",
    "\n",
    "# Copy industry share to each row\n",
    "for i in IND:\n",
    "    indShareMatrix[i] = float(IND_SHR.T[i]) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, more detail is added by employing capital formation data from the national accounts, where industry-specific investments are available for different asset groups. The commodity coverage of these assets is limited, but capturing the shares in main investment groups such as buildings and machinery is already a major improvement. In 2014, for instance, buildings and structures accounted for over 55 % of all investments. Machinery and transport equipment accounted for another 20 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross fixed capital query OK\n"
     ]
    }
   ],
   "source": [
    "# Query the data on gross fixed capital formation:\n",
    "urlDict = {\"Gross fixed capital\": \"kan/vtp/statfin_vtp_pxt_016.px\"}\n",
    "dgf.getData(urlDict, baseYear = baseYear, filters= {\"Tiedot\": [\"CP\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data:\n",
    "capData = {k: pd.read_csv(rawFolder+\"/\"+str(k)+\"_Rawdata.csv\",encoding=\"utf-8\",na_values =\".\") for k in urlDict.keys()} \n",
    "invData = capData[\"Gross fixed capital\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data:\n",
    "for col in invData:\n",
    "    if col in [\"Industry\", \"Sector\", \"Transaction\", \"Asset\", \"Type\"]:\n",
    "        invData[col] = invData[col].apply(lambda x: x.split(\" \")[0]) \n",
    "    if col == \"Industry\":\n",
    "        invData[col] = invData[col].apply(lambda k: \"{}{}\".format(\"I_\", k))\n",
    "invData.drop(\"Information\", axis =1, inplace = True)\n",
    "\n",
    "# ToDo: why are these not automatically in numeric form?\n",
    "invData[str(baseYear)] =invData[str(baseYear)].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry names in StatFin input-output data and national accounts do not directly match\n",
    "\n",
    "# Conversion of industry names from national accounts data to IO data.\n",
    "# Please check that these are up-to-date.\n",
    "differences = {\n",
    "\"I_B\": \"I_05_09\",   # Mining and quarrying \n",
    "\"I_F\": \"I_41_43\",   # Construction\n",
    "\"I_I\": \"I_55_56\",   # Accommodation and food service activities\n",
    "\"I_O\": \"I_84\",      # Public administration and social security\n",
    "\"I_681+68209+683\": \"I_68\",  # Real estate activities\n",
    "\"I_68201_68202\":   \"I_68A\"} # Operation of dwellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the old names using the dictionary specified above:\n",
    "invData.replace(differences, inplace = True)\n",
    "# Quick check that all elements of IND are found in the capital accounts data:\n",
    "for i in IND:\n",
    "    if i not in invData.Industry.unique():\n",
    "        raise ValueError(\"Industry\", i, \"not found in data!\")\n",
    "# And keep only the data for industries in IND and for sectors in \"S1 Total economy\".\n",
    "invData2 = invData[(invData[\"Industry\"].isin(IND)) & (invData[\"Sector\"] == \"S1\")].reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment assets and commodities are matched as follows:\n",
    "comAssets = {\n",
    "\"Construction\": [\"C_41_43\"],           # N111+N112 Buildings and structures --> Construction\n",
    "\"Transport\": [\"C_29\", \"C_30\"],         # N1131 Transport equipment --> Motor vehicles, Other transport equipment\n",
    "\"Machinery\": [\"C_26\", \"C_27\", \"C_28\"], # N1132+N1139 ICT equip. and other machinery --> \n",
    "                                       # Computer and electronic products, electrical equipment,\n",
    "                                       # Other machinery and equipment\n",
    "\"Intellectual\": [\"C_71\", \"C_72\"],      # N117 Intellectual property rights --> Architectural and engineering services; \n",
    "}                                      # technical testing and analysis services, \n",
    "                                       # Scientific research and development services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the investment assets specified above, filter the industry-specific investment levels.\n",
    "# The reindexing is juts to make sure that the ordering of industries is maintained.\n",
    "invLevels = {}\n",
    "invLevels[\"Construction\"] = invData2[invData2[\"Asset\"] == \"N111+N112\"].set_index(\"Industry\")[str(baseYear)].reindex(IND)\n",
    "invLevels[\"Transport\"]    = invData2[invData2[\"Asset\"] == \"N1131\"].set_index(\"Industry\")[str(baseYear)].reindex(IND)\n",
    "invLevels[\"Machinery\"]    = invData2[invData2[\"Asset\"] == \"N1132+N1139\"].set_index(\"Industry\")[str(baseYear)].reindex(IND)\n",
    "invLevels[\"Intellectual\"] = invData2[invData2[\"Asset\"] == \"N117\"].set_index(\"Industry\")[str(baseYear)].reindex(IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction I_18 set from -10.0 to zero!\n",
      "Construction I_30 set from -5.0 to zero!\n",
      "Construction I_31_32 set from -6.0 to zero!\n",
      "Construction I_58 set from -113.0 to zero!\n",
      "Construction I_80_82 set from -6.0 to zero!\n"
     ]
    }
   ],
   "source": [
    "# Set negative investment values to zero if they exist.\n",
    "# Also, turn the investment levels into industry-specific shares.\n",
    "invShares = {}\n",
    "flag = True\n",
    "for asset in invLevels:\n",
    "    for i in invLevels[asset].index:\n",
    "        if invLevels[asset].loc[i] < 0:\n",
    "            flag = False\n",
    "            value = invLevels[asset].loc[i]\n",
    "            invLevels[asset].loc[i] = 0\n",
    "            print(asset, i, \"set from\", value, \"to zero!\")\n",
    "    invShares[asset] = invLevels[asset] / invLevels[asset].sum()\n",
    "if flag:\n",
    "    print(\"Ok! No negative values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the original industry share matrix:\n",
    "for asset in comAssets:\n",
    "    for com in comAssets[asset]:\n",
    "        indShareMatrix.loc[com] = invShares[asset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, split data using the new shares:\n",
    "V2BASdom = indShareMatrix.multiply(V2BASdom, axis = \"index\")\n",
    "V2BASimp = indShareMatrix.multiply(V2BASimp, axis = \"index\")\n",
    "\n",
    "taxDict2[\"V2TAXdom\"] = indShareMatrix.multiply(taxDict2[\"V2TAXdom\"], axis =\"index\")\n",
    "taxDict2[\"V2TAXimp\"] = indShareMatrix.multiply(taxDict2[\"V2TAXimp\"], axis =\"index\")\n",
    "\n",
    "VPUR_S[\"V2PUR\"] = indShareMatrix.multiply(VPUR_S[\"V2PUR\"][\"P51\"], axis = \"index\")\n",
    "\n",
    "for k in MARGINCOMS.index:\n",
    "    for s in [\"dom\", \"imp\"]:\n",
    "        MARGIN_DICT3[\"V2MAR_\"+k+\"_\"+s] = indShareMatrix.multiply(MARGIN_DICT3[\"V2MAR_\"+s][k], axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant aggregates\n",
    "for key in ['V2MAR_imp', 'V2MAR_dom']:\n",
    "    try:\n",
    "        del MARGIN_DICT3[key]\n",
    "    except:\n",
    "        print(key, \"not found in data. No changes made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFIND is COSTS-MAKE_C : should be near zero\n",
    "allowDifference = 0.005\n",
    "DIFFIND = pd.DataFrame(0.0, index = IND, columns = [\"COSTS\", \"MAKE_C\", \"DIFFERENCE\"])\n",
    "\n",
    "#Value ad\n",
    "DIFFIND[\"COSTS\"] += V1LAB_O\n",
    "DIFFIND[\"COSTS\"] += V1CAP[\"V1CAP\"]\n",
    "DIFFIND[\"COSTS\"] += V1LND[\"V1LND\"]\n",
    "DIFFIND[\"COSTS\"] += V1PTX[\"D29MD39\"]\n",
    "DIFFIND[\"COSTS\"] += V1OCT[\"V1OCT\"]\n",
    "\n",
    "DIFFIND[\"COSTS\"] += V1BASdom.sum()\n",
    "DIFFIND[\"COSTS\"] += importMatrix[IND].sum()\n",
    "DIFFIND[\"COSTS\"] += taxDict[\"V1TAX_S\"].sum()\n",
    "DIFFIND[\"COSTS\"] += VMAR_M[\"V1\"].sum()\n",
    "\n",
    "DIFFIND[\"MAKE_C\"] += MAKE.sum()\n",
    "\n",
    "DIFFIND[\"DIFFERENCE\"] = DIFFIND[\"COSTS\"] - DIFFIND[\"MAKE_C\"]\n",
    "difData1 = DIFFIND[abs(DIFFIND[\"DIFFERENCE\"]) > allowDifference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For I_28 V1CAP is adjusted by -0.005999999997584382\n",
      "For I_31_32 V1CAP is adjusted by -0.005000000000109139\n",
      "For I_61 V1CAP is adjusted by 0.005000000000109139\n",
      "No negative values\n"
     ]
    }
   ],
   "source": [
    "# If there is a difference, transfer it into V1CAP\n",
    "for ind in difData1.index:\n",
    "    value = difData1.loc[ind][\"DIFFERENCE\"]\n",
    "    if abs(value) > 1:\n",
    "        raise ValueError(\"Assertion does not hold! Difference too big!\")\n",
    "    print(\"For\", ind, \"V1CAP is adjusted by\", value)\n",
    "    V1CAP.loc[ind] -= value\n",
    "if difData1.empty:\n",
    "    print(\"No errors, no adjustments made\")\n",
    "\n",
    "# Check that after the adjustment all entries in V1CAP remain non-negative\n",
    "cfs.check4negs(V1CAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COSTS</th>\n",
       "      <th>MAKE_C</th>\n",
       "      <th>DIFFERENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I_28</th>\n",
       "      <td>14281.995</td>\n",
       "      <td>14282.001</td>\n",
       "      <td>-0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_31_32</th>\n",
       "      <td>1637.995</td>\n",
       "      <td>1638.000</td>\n",
       "      <td>-0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_61</th>\n",
       "      <td>4295.004</td>\n",
       "      <td>4294.999</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             COSTS     MAKE_C  DIFFERENCE\n",
       "I_28     14281.995  14282.001      -0.006\n",
       "I_31_32   1637.995   1638.000      -0.005\n",
       "I_61      4295.004   4294.999       0.005"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difData1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGSALES = pd.DataFrame(0.0, index = COM, columns = [\"MARGSALES\"])\n",
    "for i in MARGINCOMS.index:\n",
    "    MARGSALES[\"MARGSALES\"][i] = abs(MARGINCOMS[i])\n",
    "\n",
    "# DIFFCOM is COM_OUTPUT - COM_USE : should be zero\n",
    "DIFFCOM = pd.DataFrame(0.0, index = COM, columns = [\"OUTPUT\", \"USE\", \"DIFFERENCE\"])\n",
    "\n",
    "DIFFCOM[\"OUTPUT\"] += MAKE.sum(axis=1)\n",
    "\n",
    "DIFFCOM[\"USE\"] += V1BASdom.sum(axis = 1)\n",
    "DIFFCOM[\"USE\"] += V2BASdom.sum(axis = 1)\n",
    "DIFFCOM[\"USE\"] += V3BASdom\n",
    "DIFFCOM[\"USE\"] += V4BAS[\"V4BAS\"]\n",
    "DIFFCOM[\"USE\"] += V5BASdom\n",
    "DIFFCOM[\"USE\"] += V6BASdom\n",
    "DIFFCOM[\"USE\"] += MARGSALES[\"MARGSALES\"]\n",
    "\n",
    "DIFFCOM[\"DIFFERENCE\"] = DIFFCOM[\"OUTPUT\"] - DIFFCOM[\"USE\"]\n",
    "\n",
    "difData2 = DIFFCOM[abs(DIFFCOM[\"DIFFERENCE\"]) > allowDifference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C_37_39 V6BAS is adjusted by 0.005000000000109139\n",
      "For C_49 V6BAS is adjusted by 0.0059999999994033715\n",
      "For C_77 V6BAS is adjusted by 0.006999999998697604\n"
     ]
    }
   ],
   "source": [
    "for com in difData2.index:\n",
    "    value = difData2.loc[com][\"DIFFERENCE\"]\n",
    "    if abs(value) > 1:\n",
    "        raise ValueError(\"Assertion does not hold! Difference too big!\")\n",
    "    print(\"For\", com, \"V6BAS is adjusted by\", value)\n",
    "    V6BASdom.loc[com] +=  value\n",
    "if difData2.empty:\n",
    "    print(\"No errors, no adjustments made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters and coefficients for model homogenity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramSheets =[sheet for sheet in pd.read_excel(\"supplementaryData/PARAMETERS64.xlsx\", sheet_name=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramDict = {}\n",
    "for sheet in paramSheets:\n",
    "    paramDict[sheet] = pd.read_excel(\"supplementaryData/PARAMETERS64.xlsx\", sheet_name = sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramNames = {\n",
    "\"1ARM\": \"Intermediate Armington\",\n",
    "\"2ARM\": \"Investment Armington\",\n",
    "\"3ARM\": \"Households Armington\",\n",
    "\"ITEX\": \"Flag, >0.5 for individual export coms, else collective export\",\n",
    "\"LCOM\": \"Flag for regional extension, >0.5 for local coms, else national\",\n",
    "\"LIND\": \"Local industries\",\n",
    "\"P018\": \"Traditional Export Elasticities\",\n",
    "\"P028\": \"Primary Factor Sigma\",\n",
    "\"SCET\": \"Output Sigma\",\n",
    "\"SLAB\": \"Labour Sigma\",\n",
    "\"XPEL\": \"Household Expenditure Elasticities\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data as numpy arrays before exporting them as HAR files\n",
    "V1BAS = np.stack((V1BASdom.values, V1BASimp.values), axis=1)\n",
    "V2BAS = np.stack((V2BASdom.values, V2BASimp.values), axis=1)\n",
    "\n",
    "V1TAX = np.stack((taxDict2[\"V1TAXdom\"].values, taxDict2[\"V1TAXimp\"].values), axis = 1)\n",
    "V2TAX = np.stack((taxDict2[\"V2TAXdom\"].values, taxDict2[\"V2TAXimp\"].values), axis = 1)\n",
    "V3TAX = pd.concat([taxDict2[\"V3TAXdom\"],taxDict2[\"V3TAXimp\"]], axis = 1)\n",
    "V4TAX = taxDict[\"V4TAX_S\"]\n",
    "V5TAX = np.stack((taxDict2[\"V5TAXdom\"].values, taxDict2[\"V5TAXimp\"].values), axis = 1)\n",
    "V6TAX = np.stack((taxDict2[\"V6TAXdom\"].values, taxDict2[\"V6TAXimp\"].values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note dstack = along the 3rd dimension for margins!\n",
    "V1MAR = np.stack([\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V1MAR\" in key and \"dom\" in key]),\\\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V1MAR\" in key and \"imp\" in key])], axis=1)\n",
    "\n",
    "V2MAR = np.stack([\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V2MAR\" in key and \"dom\" in key]),\\\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V2MAR\" in key and \"imp\" in key])], axis=1)\n",
    "\n",
    "V3MAR = np.stack((MARGIN_DICT3[\"V3MAR_dom\"].values, MARGIN_DICT3[\"V3MAR_imp\"].values), axis = 1)\n",
    "V4MAR = MARGIN_DICT3[\"V4MAR\"]\n",
    "V5MAR = np.stack((MARGIN_DICT3[\"V5MAR_dom\"].values, MARGIN_DICT3[\"V5MAR_imp\"].values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDims = {\n",
    "\"COM\": COM,            # Commodities\n",
    "\"IND\": IND,            # Industries\n",
    "\"OCC\": OCC,            # Occupations\n",
    "\"SRC\": [\"DOM\", \"IMP\"], # Sources\n",
    "\"MAR\": MAR}            # Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseData={\n",
    "#coefficient name: (dataset, header name, long name, [list of dimensions])\n",
    "\"V1CAP\": (V1CAP, \"1CAP\", \"Capital rentals\", [\"IND\"]),\n",
    "\"V1LND\": (V1LND, \"1LND\", \"Land rentals\", [\"IND\"]),\n",
    "\"V1LAB\": (V1LAB, \"1LAB\", \"Labor compensation\", [\"IND\", \"OCC\"]),\n",
    "\"MAKE\":  (MAKE,  \"MAKE\", \"Multi-production matrix\", [\"COM\", \"IND\"]),\n",
    "\"V1PTX\": (V1PTX, \"1PTX\", \"Production tax\", [\"IND\"]),\n",
    "\"V0TAR\": (V0TAR, \"0TAR\", \"Tariff revenue\", [\"COM\"]),\n",
    "\"V1OCT\": (V1OCT, \"1OCT\", \"Other cost ticket\", [\"IND\"]),\n",
    "# Basic flows    \n",
    "\"V1BAS\": (V1BAS, \"1BAS\", \"Intermediate basic\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V2BAS\": (V2BAS, \"2BAS\", \"Investment basic\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V3BAS\": (V3BAS, \"3BAS\", \"Household basic\", [\"COM\", \"SRC\"]),\n",
    "\"V4BAS\": (V4BAS, \"4BAS\", \"Export basic\", [\"COM\"]),\n",
    "\"V4BASimp\": (V4BASimp, \"4BAi\", \"Export basic\", [\"COM\"]),   \n",
    "\"V5BAS\": (V5BAS, \"5BAS\", \"Government basic\", [\"COM\", \"SRC\"]),\n",
    "\"V6BAS\": (V6BAS, \"6BAS\", \"Inventories basic\", [\"COM\", \"SRC\"]),\n",
    "# Basic taxes    \n",
    "\"V1TAX\": (V1TAX, \"1TAX\", \"Intermediate tax\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V2TAX\": (V2TAX, \"2TAX\", \"Investment tax\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V3TAX\": (V3TAX, \"3TAX\", \"Household tax\", [\"COM\", \"SRC\"]),\n",
    "\"V4TAX\": (V4TAX, \"4TAX\", \"Export tax\", [\"COM\"]),\n",
    "\"V5TAX\": (V5TAX, \"5TAX\", \"Government tax\", [\"COM\", \"SRC\"]),\n",
    "\"V6TAX\": (V6TAX, \"6TAX\", \"Inventories tax\", [\"COM\", \"SRC\"]),\n",
    "# Margins\n",
    "\"V1MAR\": (V1MAR, \"1MAR\", \"Intermediate margins\", [\"COM\", \"SRC\", \"IND\", \"MAR\"]),\n",
    "\"V2MAR\": (V2MAR, \"2MAR\", \"Investment margins\", [\"COM\", \"SRC\", \"IND\", \"MAR\"]),\n",
    "\"V3MAR\": (V3MAR, \"3MAR\", \"Household margins\", [\"COM\", \"SRC\", \"MAR\"]),\n",
    "\"V4MAR\": (V4MAR, \"4MAR\", \"Export margins\", [\"COM\", \"MAR\"]),\n",
    "\"V5MAR\": (V5MAR, \"5MAR\", \"Government margins\", [\"COM\", \"SRC\", \"MAR\"]),\n",
    "# Parameters\n",
    "\"SIGMA1\": (paramDict[\"1ARM\"], \"1ARM\", \"Intermediate Armington\", [\"COM\"]),\n",
    "\"SIGMA2\": (paramDict[\"2ARM\"], \"2ARM\", \"Investment Armington\", [\"COM\"]),\n",
    "\"SIGMA3\": (paramDict[\"3ARM\"], \"3ARM\", \"Household Armington\", [\"COM\"]),\n",
    "\"IsIndivExp\": (paramDict[\"ITEX\"], \"ITEX\", \"Flag for individual export commodities\", [\"COM\"]),    \n",
    "\"IsLocCom\":   (paramDict[\"LCOM\"], \"LCOM\", \"Flag for regional extension > 0.5 for local coms, els national\", [\"COM\"]),\n",
    "\"EXP_ELAST\":  (paramDict[\"P018\"], \"P018\", \"Individual export elasticities\", [\"COM\"]),\n",
    "\"SIGMA1PRIM\": (paramDict[\"P028\"], \"P028\", \"Primary factor sigma\", [\"IND\"]),\n",
    "\"SIGMA1OUT\":  (paramDict[\"SCET\"], \"SCET\", \"Output sigma\", [\"IND\"]),\n",
    "\"SIGMA1LAB\":  (paramDict[\"SLAB\"], \"SLAB\", \"Labour sigma\", [\"IND\"]),\n",
    "\"EPS\": (paramDict[\"XPEL\"], \"XPEL\", \"Household expenditure elasticities\", [\"COM\"]),\n",
    "# Constants\n",
    "\"EXP_ELAST_NT\": (2.0, \"EXNT\", \"Collective export elasticity\", []),\n",
    "\"FRISCH\": (1.5, \"P021\", \"Frisch parameter\", []),\n",
    "\"BASEYEAR\": (baseYear, \"BYER\", \"Data base year\", [],),\n",
    "\"ALPHA1\": (0.4, \"ALF1\", \"Wage adaptation coefficient\", []),\n",
    "\"ALPHA2\": (0.0, \"ALF2\", \"Employment adaptation coefficient\", []),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dimensions as sets. Also include the regional data:\n",
    "output = {**allDims, **baseData}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf.data2har(output, allDims).writeToDisk(harFolder+\"/basedata64.har\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating AGGSUP.har supplementary file for aggregating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data used for weighted aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1PRIM = V1LAB_O + V1CAP[\"V1CAP\"] + V1LND[\"V1LND\"]\n",
    "V1MAT = VPUR_S[\"V1PUR\"].sum()\n",
    "V1CST = V1PRIM + V1OCT[\"V1OCT\"] + V1MAT\n",
    "V1TOT = V1CST + V1PTX[\"D29MD39\"]\n",
    "V2TOT = VPUR_S[\"V2PUR\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1PUR_SI = VPUR_S[\"V1PUR\"].sum(axis=1)\n",
    "V2PUR_SI = VPUR_S[\"V2PUR\"].sum(axis=1)\n",
    "V3PUR_S  = VPUR_S[\"V3PUR\"][\"P3_S14\"]\n",
    "V4PUR    = VPUR_S[\"V4PUR\"][\"P6K\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mappings for direct aggregation\n",
    "\n",
    "Commodities and Industries are mapped to match the level at which regional data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query for regional industy classification: (StatFin: Output and employment by region)\n",
    "regIndRaw = [x[\"values\"] for x in dgf.getParams(\"statfin_altp_pxt_008.px\", \"names\") if x[\"code\"] == \"Toimiala\"][0]\n",
    "# ['0', '01', '02_03', '05_09', '10_12', '13_15', '16', '17_18', '19_22', '23', '24_25', '26_27', \n",
    "# '28', '29_30', '31_33', '35_39', '41_43', '45_47', '49_53', '55_56', '58_63', '64_66', '681+68209+683', \n",
    "# '68201_68202', '69_75', '77_82', '84', '85', '86_88', '90_96', '97_98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "renameInd = {           # From regional accounts naming convention to input-output convention\n",
    "\"681+68209+683\": \"68\",  # Other real estate activities  --> Real estate activities\n",
    "\"68201_68202\"  : \"68A\"} # Letting and operation of dwellings  --> Operation of dwellings and residential real estate\n",
    "\n",
    "regInd = [renameInd.get(n, n) for n in regIndRaw if n != \"0\"] # Rename and drop \"0\" (Industries total)\n",
    "\n",
    "# Last, add the prefix \"I_\" to all regional industries:\n",
    "regInd = [\"I_\"+i for i in regInd]\n",
    "# And prefix \"C_\" for commodities:\n",
    "regCom = [\"C_\" + c[2:] for c in regInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from IND to regInd and COM to regCom\n",
    "MIND = mf.mapperFunction(IND, regInd)\n",
    "MCOM = mf.mapperFunction(COM, regCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggSup={\n",
    "#coefficient name: (dataset, header name, long name, [list of dimensions])\n",
    "\"V1TOT\":  (V1TOT,    \"1TOT\", \"Industry output\", [\"IND\"]),\n",
    "\"V2TOT\":  (V2TOT,    \"2TOT\", \"Investment by industry\", [\"IND\"]),\n",
    "\"V1PRIM\": (V1PRIM,   \"VLAD\", \"Total factor input to industry\", [\"IND\"]),\n",
    "\"V1LAB_O\":(V1LAB_O,  \"1LAB\", \"Industry wages\", [\"IND\"]),\n",
    "\"V1PUR\":  (V1PUR_SI, \"1PUR\", \"Intermediate use at purch. price\", [\"COM\"]),\n",
    "\"V2PUR\":  (V2PUR_SI, \"2PUR\", \"Investment use at purch. price\", [\"COM\"]),\n",
    "\"V3PUR\":  (V3PUR_S,  \"3PUR\", \"Consumption at purch. price\", [\"COM\"]),\n",
    "\"V4PUR\":  (V4PUR,    \"4PUR\", \"Export at purch. price\", [\"COM\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAGG = [\n",
    "# Headers that are used in weighted aggregations for elasticities and ratios\n",
    "\"1ARM 1PUR\",\n",
    "\"2ARM 2PUR\",\n",
    "\"3ARM 3PUR\",\n",
    "\"XPEL 3PUR\",\n",
    "\"P018 4PUR\",\n",
    "\"P028 VLAD\",\n",
    "\"SLAB 1LAB\",\n",
    "\"SCET 1TOT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggDims = {\n",
    "\"COM\": COM,     # All commodities \n",
    "\"IND\": IND,     # All industries\n",
    "\"ACOM\": regCom,  # Regional commodities\n",
    "\"AIND\": regInd,  # Regional industries\n",
    "\"WAGG\": WAGG,    # Headers for weighted aggregation\n",
    "\"MCOM\": [str(c) for c in MCOM.values()],\n",
    "\"MIND\": [str(i) for i in MIND.values()]\n",
    "}\n",
    "\n",
    "aggSupData = {**aggDims, **aggSup}\n",
    "aggSupHar = hwf.data2har(aggSupData, aggDims)\n",
    "\n",
    "# Mappings are created to MCOM and MIND.\n",
    "# Mappings must be specified using long_name. Note! 70 characters.\n",
    "\n",
    "aggSupHar.getHeaderArrayObj(\"MCOM\").__setitem__(\"long_name\", \"Mapping MCOM from COM(64) to ACOM(30)                                 \")\n",
    "aggSupHar.getHeaderArrayObj(\"MIND\").__setitem__(\"long_name\", \"Mapping MIND from IND(64) to AIND(30)                                 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggSupHar.writeToDisk(harFolder+\"/AGGSUP.har\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save clean/basedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_folder = \"interdata\"\n",
    "os.makedirs(inter_folder, exist_ok=True)\n",
    "pickle.dump(cleanData, open(inter_folder+\"/cleanData.p\", \"wb\"))\n",
    "\n",
    "table_dims = {\"COM\": COM, \n",
    "              \"IND\": IND,\n",
    "              \"finUse\": finUse,\n",
    "              \"valAdd\": valAdd,\n",
    "              \"supComp\": supComp}\n",
    "\n",
    "pickle.dump(table_dims, open(inter_folder+\"/table_dims.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
