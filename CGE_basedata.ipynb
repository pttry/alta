{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a core CGE model database for Finland from published data\n",
    "\n",
    "\n",
    "This iPython notebook builds a core CGE model database for Finland using published national accounts data. First, raw data are queried from the Statistics Finland API, cleaned and filtered. Next, the data are aggregated to a suitable level, and the balancing conditions are checked. Last, the resulting dataset is processed to match the requirements of a CGE model database. The steps are explained in detail in the paper \"Constructing a CGE Database Using GEMPACK for an African Country\" by Roos, Adams and van Heerden. This notebook replicates most of those steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NATIONAL DATA (64 industries, 64 commodities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic modules\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# HARPY module by Centre of Policy Studies for writing data from pandas DataFrames into Header Array (.har) files.\n",
    "# Available at https://github.com/GEMPACKsoftware/HARPY or -pip install by harpy3\n",
    "from harpy.har_file import HarFileObj\n",
    "from harpy.header_array import HeaderArrayObj as HAO\n",
    "\n",
    "import dataGetterFunction as dgf\n",
    "import harWriterFunction  as hwf\n",
    "import checkerFunctions as cfs\n",
    "import mapperFunction as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose base year for data:\n",
    "baseYear = 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REMOVE OLD DATA FROM WORKING DIRECTORY? (True / False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = False\n",
    "\n",
    "# Remove old files from the working directory. \n",
    "# All supplementary data is in .xlsx format, so don't remove those.\n",
    "if remove:\n",
    "    for filename in os.listdir():\n",
    "        if filename.endswith('.csv')\\\n",
    "        or filename.endswith('.har'):\n",
    "            os.unlink(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify data location in the Statfin API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data location as a dictionary. The dictionary key is a (user-specified) name\n",
    "# for the data, and the key must be the actual location. If error occur, use the\n",
    "# dgf.searchStatfin(\"...\") to check the data location.\n",
    "\n",
    "urlDict = {\n",
    "\"Supply table at basic prices\":          \"kan/pt/statfin_pt_pxt_001.px\",\n",
    "\"Use table at basic prices\":             \"kan/pt/statfin_pt_pxt_002.px\",\n",
    "\"Use table at purchasers prices\":        \"kan/pt/statfin_pt_pxt_003.px\",\n",
    "\"Use table for imports at basic prices\": \"kan/pt/statfin_pt_pxt_005.px\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform query.\n",
    "# Raw data files should appear in the working directory.\n",
    "\n",
    "dgf.getData(urlDict, baseYear = baseYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw data:\n",
    "ioData = {k: pd.read_csv(str(k)+\"_Rawdata.csv\",encoding=\"utf-8\",na_values =\".\") for k in urlDict.keys()} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "The function defined below renames all industries and commodities in raw data by replacing the long names with the representative code strings. It also adds different prefixes for industries (\"I_\") and commodities (\"C_\"). For example \"01 Agriculture and hunting\" becomes \"I_01\", and \"10_12 Food products, beverages and tobacco\" becomes \"C_10_12\". Also, to avoid later errors in GEMPACK, all instances of \"/\" are replaced with an underscore.\n",
    "\n",
    "All industries and commodities are then collected to the lists IND and COM. They should be identical in size: 64 industries and 64 commodities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitNrename(df, attribute, prefix):\n",
    "    \"\"\"\n",
    "    This function takes in a DataFrame and cleans it from the long Statfin naming convention\n",
    "    \"indNum ind longname\" to the model convention \"PREFIX_indNum\".\n",
    "    E.g. \"01 Agriculture and hunting\" becomes \"I_01\" and \"17 Paper and paper products\" becomes \"C_17\".\n",
    "    \n",
    "    Inputs: DataFrame to be cleaned, attribute (column, index...) and a prefix (\"C_\" or \"I_\").\n",
    "    \"\"\"\n",
    "    for x in getattr(df, attribute):\n",
    "        dataCode = x.split(\" \")[0]\n",
    "        if \"/\" in dataCode:\n",
    "            dataCode = dataCode.replace(\"/\",\"_\")\n",
    "        if dataCode[0].isdigit():\n",
    "            newName = prefix + dataCode\n",
    "        else:\n",
    "            newName = dataCode\n",
    "        df.rename(**{attribute: {x:newName}}, inplace = True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ioData:\n",
    "    # Replace missing values with zeros:\n",
    "    ioData[i].fillna(0, inplace = True)\n",
    "    # Use the product column as index:\n",
    "    ioData[i].set_index(\"Product\", inplace = True)\n",
    "    # Drop redundant columns if they exist:\n",
    "    for redundant in [\"Year\", \"0 Industries total\"]:\n",
    "        if redundant in ioData[i].columns:\n",
    "            ioData[i].drop(redundant, axis = 1, inplace = True)\n",
    "    # Perform the renaming using the splitNrename function.\n",
    "    # Note: commodities are in index and industries are in columns.\n",
    "    for attr, prefix in {\"index\": \"C_\", \"columns\": \"I_\"}.items():\n",
    "        splitNrename(ioData[i], attr, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND = [ind for ind in ioData[\"Supply table at basic prices\"].columns if ind[0:2] == \"I_\"]\n",
    "COM = [com for com in ioData[\"Supply table at basic prices\"].index if com[0:2] == \"C_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the COM and IND dimensions are equal in length (original data is symmetrical):\n",
    "print(len(IND) == len(COM))\n",
    "print(\"Length is\", len(IND))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into individual dataframes:\n",
    "usetable_PP_raw    = ioData[\"Use table at purchasers prices\"]\n",
    "usetable_BP_raw    = ioData[\"Use table at basic prices\"]\n",
    "usetableImp_BP_raw = ioData[\"Use table for imports at basic prices\"]\n",
    "supplytable_BP_raw = ioData[\"Supply table at basic prices\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define other types of uses and supply sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "finUse = [   # Final users\n",
    "\"P51\",       # Gross fixed capital formation\n",
    "\"P52\",       # Changes in inventories\n",
    "\"P6K\",       # Exports\n",
    "\"P3_S13\",    # Government consumption\n",
    "\"P3_S14\",    # Household consumption\n",
    "\"P3_S15\"]    # Non-profit consumption -> is aggregated to household consumption   \n",
    "\n",
    "valAdd = [   # Value add components\n",
    "\"D1\",        # Compensation of employees\n",
    "\"D29MD39\",   # Other net taxes on production\n",
    "\"P51C\",      # Consumption of fixed capital\n",
    "\"B13NT\"]     # Operating surplus + mixed income \n",
    "    \n",
    "supCmp = [   # Supply components\n",
    "\"P7R_CIF\",   # Imports at c.i.f. prices\n",
    "\"TRTP_MARG\", # Trade and transport margins\n",
    "\"D21N\"]      # Taxes less subsidies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter raw data and store it in a new dictionary cleanData:\n",
    "cleanData = {}\n",
    "cleanData[\"usetable_PP\"] = usetable_PP_raw.reindex(COM + valAdd)[IND + finUse]\n",
    "cleanData[\"usetable_BP\"] = usetable_BP_raw.reindex(COM + valAdd)[IND + finUse]\n",
    "cleanData[\"supplytable_BP\"]  = supplytable_BP_raw.reindex(COM)[IND+supCmp]\n",
    "cleanData[\"usetable_Imp_BP\"] = usetableImp_BP_raw.reindex(COM + valAdd)[IND + finUse].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the original data:\n",
    "\n",
    "#### Check for negative values in original data\n",
    "\n",
    "Negative values are only allowed for changes in inventories. Check that no negative values exist in the original data. Possible negative values, if small, are set to zero and distributed into changes in inventories (user code \"P52\"). Re-run this block to check that no negative values remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negativesList = []\n",
    "for commodity in COM:\n",
    "    for user in IND + finUse:\n",
    "        for priceType in [\"PP\", \"BP\"]: # Purchaser price, basic price\n",
    "            if user != \"P52\": # Negative values are allowed in inventory changes, so exclude those\n",
    "                dataLocation = cleanData[\"usetable_\"+priceType].loc[commodity]\n",
    "                if dataLocation[user] < 0:                              # if the value is negative\n",
    "                    negValue = dataLocation[user]                       # save the location\n",
    "                    negativesList.append((user, commodity, negValue))   # store it to the negativesList for reporting\n",
    "                    dataLocation[\"P52\"] += negValue                     # assign the neg. value to changes in inventories\n",
    "                    dataLocation[user] = 0                              # set the original neg. value to zero\n",
    "                    print(priceType, user, commodity,\": value\", negValue, \" assigned to changes in inventories!\")\n",
    "                    \n",
    "if not negativesList:\n",
    "    print(\"No negative values encountered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that current price GDP from income side equals GDP from expenditure side (well enough):\n",
    "GDPexp = cleanData[\"usetable_PP\"].loc[COM][finUse].sum().sum() - cleanData[\"supplytable_BP\"][\"P7R_CIF\"].sum()\n",
    "GDPinc = cleanData[\"usetable_PP\"].loc[valAdd].sum().sum() + cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"].sum()\n",
    "\n",
    "print(\"GDPexp is\", GDPexp,\"\\nGDPinc is\", GDPinc, \"\\nDifference is\", GDPexp-GDPinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that aggregate supply equals aggregate demand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowDifference = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs.checkColSums(cleanData[\"supplytable_BP\"].loc[COM], cleanData[\"usetable_PP\"].loc[COM], allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that national accounts identities hold in original data:\n",
    "\n",
    "PP = BP - net taxes - margins from producer side + margins from user side\n",
    "\n",
    "Basic flows = BP - margins = PP - taxes - margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check1: pur - tax = bas prices (differences in margins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All match!\n"
     ]
    }
   ],
   "source": [
    "# Margins inferred from data:\n",
    "margtest=(cleanData[\"usetable_PP\"].loc[COM] -\\\n",
    "          cleanData[\"usetable_BP\"].loc[COM]).sum(axis=1)-cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"]\n",
    "# Actual margins data\n",
    "realmarg = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "\n",
    "check1 = pd.DataFrame(0.0, index=COM, columns=[\"calculated\", \"actual\"])\n",
    "check1[\"calculated\"] = realmarg\n",
    "check1[\"actual\"] = margtest\n",
    "check1[\"difference\"] = check1[\"calculated\"] - check1[\"actual\"]\n",
    "if not any (check1[\"difference\"] > allowDifference):\n",
    "    print(\"All match!\")\n",
    "else:\n",
    "    print(check1[abs(check1[\"difference\"]) > allowDifference])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check2: total sum of differences is near zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(check1[\"actual\"].sum()) < allowDifference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check3: domestic use equals domestic supply (MAKE_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that supply and use by commodity is balanced:\n",
    "domUse = cleanData[\"usetable_BP\"].loc[COM].sum(axis=1) - cleanData[\"supplytable_BP\"][\"P7R_CIF\"]\n",
    "MAKE_I = cleanData[\"supplytable_BP\"][IND].sum(axis=1)\n",
    "\n",
    "check3 = pd.DataFrame(0, index=COM, columns=[\"BASuse\", \"MAKE\", \"difference\"])\n",
    "check3[\"BASuse\"] = domUse\n",
    "check3[\"MAKE\"] = MAKE_I\n",
    "check3[\"difference\"] = check3[\"BASuse\"] - check3[\"MAKE\"]\n",
    "if not any (check3[\"difference\"] > allowDifference):\n",
    "    print(\"All match!\")\n",
    "else:\n",
    "    print(check3[abs(check3[\"difference\"]) > allowDifference])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check4: Basic price - basic flows - margins_C = 0, where \n",
    "\n",
    "basic flows =  PUR - tax - margins_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define total margins used per commodity\n",
    "MAR_M = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "for i in MAR_M.index:\n",
    "    if MAR_M.loc[i] < 0:\n",
    "        MAR_M.loc[i] = 0      \n",
    "# And total margins produced per margin commodity\n",
    "MAR_C = cleanData[\"supplytable_BP\"].loc[COM][\"TRTP_MARG\"]\n",
    "for c in MAR_C.index:\n",
    "    if MAR_C.loc[c] >= 0:\n",
    "        MAR_C.loc[c] = 0\n",
    "    else:\n",
    "        MAR_C.loc[c] = MAR_C.loc[c] * (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total flows:\n",
    "flows_U = cleanData[\"usetable_PP\"].loc[COM].sum(axis=1) - cleanData[\"supplytable_BP\"].loc[COM][\"D21N\"] - MAR_M\n",
    "\n",
    "# Check:\n",
    "errors = []\n",
    "check4 = cleanData[\"usetable_BP\"].loc[COM].sum(axis=1) - flows_U - MAR_C\n",
    "for k in check4.index:\n",
    "    if abs(check4.loc[k]) > allowDifference:\n",
    "        errors.append(check4.loc[k])\n",
    "if not errors:\n",
    "    print(\"No errors\")\n",
    "else:\n",
    "    print(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-profit consumption P3_S15 is aggregated to household consumption P3_S14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cleanData:\n",
    "    if \"P3_S15\" in cleanData[i]:\n",
    "        cleanData[i][\"P3_S14\"] += cleanData[i][\"P3_S15\"]\n",
    "        cleanData[i].drop(\"P3_S15\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor payments\n",
    "\n",
    "### V1LAB (palkansaajakorvaukset)\n",
    "\n",
    "* From Use Table at purchaser's prices, select all industries and D1 (Compensation of employees). \n",
    "* Split D1 using occupational shares from mitenna database (see /supplementaryData/occupationalDataInfo.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in raw occupational data from MITENNA supplementary file:\n",
    "OCC_levels = pd.read_excel(\"supplementaryData/MITENNA_OCC60.xlsx\")\n",
    "OCC_levels.fillna(0, inplace=True)\n",
    "# Drop redundant columns:\n",
    "OCC_levels.drop([\"Missing data\", \"Grand total\"], axis = 1, inplace = True)\n",
    "# Drop redundant rows:\n",
    "OCC_levels.drop([\"00000 Industry unknown\", \n",
    "                 \"Grand total\",\n",
    "                 \"99000 Activities of extraterritorial organisations and bodies\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the index names and column names.\n",
    "# For occupations: \"02.3 Metal workers\" becomes \"O_02_3\"\n",
    "# For industries:  \"01410 Raising of dairy cattle\" becomes \"I_01410, etc.\n",
    "\n",
    "for occupation in OCC_levels:\n",
    "    newName = \"O_\"+occupation.split(\" \")[0].replace(\".\",\"_\")\n",
    "    OCC_levels.rename(columns = {occupation:newName}, inplace = True)\n",
    "for industry in OCC_levels.index:\n",
    "    # If industry name starts with a letter (there might be some aggregate sets in MITENNA data), drop it, but check that the \n",
    "    # number of employed in that sector is small enough to not cause any harm. \n",
    "    # TODO: rename the aggregate industries to numeric form instead of dropping them.\n",
    "    if re.search('[a-zA-Z]', industry[0]): \n",
    "        print(\"Dropped\", industry,\"with a total employment of\", OCC_levels.loc[industry].sum(), \"persons.\")\n",
    "        OCC_levels.drop(industry, inplace = True)\n",
    "    newName = \"I_\"+industry.split(\" \")[0]\n",
    "    OCC_levels.rename(index = {industry:newName}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the +850 mitenna industries to a single list\n",
    "mitennaIndustries = OCC_levels.index.tolist()\n",
    "# And create a mapping from Mitenna to Statfin level\n",
    "mitennaIndMapper = mf.mapperFunction(mitennaIndustries, IND, exceptions={\"I_68A\":[\"I_68201\", \"I_68202\"]})\n",
    "\n",
    "# CHECK THE mitennaIndMapper ALSO MANUALLY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the occupational data using the mappings specified above:\n",
    "OCC_levels[\"MAP_HERE\"] = pd.Series(mitennaIndMapper)\n",
    "OCC_levels = OCC_levels.groupby([\"MAP_HERE\"], sort = False).sum()\n",
    "OCC_levels = OCC_levels.reindex(IND).fillna(0)\n",
    "\n",
    "# Calculate industry specific occupation shares:\n",
    "OCCshares = OCC_levels.divide(OCC_levels.loc[IND].sum(axis=1), axis = \"index\").fillna(0)\n",
    "\n",
    "# Store the occupations dimension OCC to a list:\n",
    "OCC = OCC_levels.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Split the original labor compensation data:\n",
    "V1LAB_O = cleanData[\"usetable_BP\"].loc[\"D1\"][IND]\n",
    "V1LAB   = OCCshares.multiply(V1LAB_O, axis = \"index\")\n",
    "\n",
    "# Last, check that column sums still match the original data:\n",
    "cfs.checkCols(V1LAB.sum(axis=1), V1LAB_O, allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1CAP (pääomakorvaukset)\n",
    "V1CAP is calculated for each industry by summing the capital depriciation (P51C) and operating surplus (B13NT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No negative values\n"
     ]
    }
   ],
   "source": [
    "V1CAP = cleanData[\"usetable_BP\"].loc[[\"P51C\", \"B13NT\"]].sum()\n",
    "V1CAP = V1CAP[IND].to_frame(\"V1CAP\")\n",
    "\n",
    "# Check that no industries have negative capital flows\n",
    "cfs.check4negs(V1CAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1LND (korvaukset maasta)\n",
    "\n",
    "Next, the land rentals (V1LND) are separated for the land using sectors (agriculture, forestry, and mining) from V1CAP using the following shares:\n",
    "\n",
    "* Agriculture: 15.0% $^{1}$ \n",
    "* Forestry: 66% $^{2}$ \n",
    "* Mining and quarrying: 7.7% $^{2}$ \n",
    "\n",
    "**TODO: tarkista osuudet!! Olisiko PTT:llä tarkemmat arviot maa- ja metsätalouden maatalousmaan osuudesta suhteessa koko pääomakantaan?**\n",
    "\n",
    "\n",
    "1. Land value / total farm assets. Source:  Statfin >> Agriculture, Forestry and Fishery >> Statistics on the finances of agricultural and forestry enterprises (35/41, Year 2014, Entire country)\n",
    "\n",
    "2. The share of land improvements / total assets. Source:  Statfin >> National Accounts >> Annual national accounts >> 017 -- Gross capital, Net capital, consumption and retirements of fixed capital 1975-2016 (N1123/TOT, Gross stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize V1LND to a zero vector:\n",
    "V1LND = pd.DataFrame(0.0, index=IND, columns=[\"V1LND\"])\n",
    "\n",
    "# Specify lists of land-using industries:\n",
    "agrInd = [\"I_01\"]          # Agriculture\n",
    "forInd = [\"I_02\", \"I_03\"]  # Forest industry\n",
    "minInd = [\"I_05_09\"]       # Mining\n",
    "\n",
    "V1LND.loc[agrInd] = V1CAP.loc[agrInd].multiply(0.150)\n",
    "V1LND.loc[forInd] = V1CAP.loc[forInd].multiply(0.66)\n",
    "V1LND.loc[minInd] = V1CAP.loc[minInd].multiply(0.077)\n",
    "\n",
    "# Last, to avoid double counting, subtract V1LND from V1CAP\n",
    "V1CAP[\"V1CAP\"] -= V1LND[\"V1LND\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store user-specific purchaser's price values V1PUR-V6PUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "userNames = {\n",
    "\"V1\": IND,          # Industry\n",
    "\"V2\": [\"P51\"],      # Investment\n",
    "\"V3\": [\"P3_S14\"],   # Households\n",
    "\"V4\": [\"P6K\"],      # Export\n",
    "\"V5\": [\"P3_S13\"],   # Government\n",
    "\"V6\": [\"P52\"]}      # Inventories\n",
    "\n",
    "userList = [item for sublist in userNames.values() for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "VPUR_S = {} # VPUR summed over source dimension S (domestic or imported)\n",
    "for i in userNames:\n",
    "    VPUR_S[i+\"PUR\"] = cleanData[\"usetable_PP\"].loc[COM][userNames[i]]\n",
    "VPUR_US = cleanData[\"usetable_PP\"].loc[COM].sum(axis=1) # VPUR summed over dimensions source S and user U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE matrix (multi-production matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make matrix is simply extracted from the basic price supply table:\n",
    "MAKE = cleanData[\"supplytable_BP\"].loc[COM][IND].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1PTX (tuotantoverot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1PTX = pd.DataFrame(cleanData[\"usetable_BP\"].loc[\"D29MD39\"][IND].copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V0TAR (tariff revenue)\n",
    "\n",
    "**TODO: Laske hyödykekohtainen tuontitulli tarkemmin!! Nyt vuosittainen kumulatiivinen kanto on jaettu tasan tuontihyödykkeiden kesken (tullin osuus per tuontieuro)!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total tariff revenue is:\n",
    "V0TAR_tot = 163.090 # m€\n",
    "# Source: Finnish customs at uljas.tulli.fi\n",
    "# State revenue debited by Finnish Customs from 2001, indicator D.1.1.\n",
    "\n",
    "# Total commodity specific imports are:\n",
    "impByCom = cleanData[\"supplytable_BP\"][\"P7R_CIF\"].copy()\n",
    "\n",
    "\n",
    "# Tariff data is only collected from goods classified in the Combined Nomenclature (CN).\n",
    "# Thus, set everything beyond C_32 to zero:\n",
    "for commodity in COM:\n",
    "    if int(commodity[2:4]) >= 33:\n",
    "        impByCom[commodity] = 0\n",
    "        \n",
    "# Imports are at C.I.F prices, so we can calculate the tariff share as:\n",
    "tariffShare = V0TAR_tot / impByCom.sum() \n",
    "\n",
    "V0TAR = (impByCom * tariffShare).to_frame(name=\"V0TAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V1OCT (other cost ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, the other cost ticket is set to zero. In later stages, it can be used for e.g. for maintaining data balance.\n",
    "V1OCT = pd.DataFrame(0.0, index = IND, columns = [\"V1OCT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import shares\n",
    "\n",
    "The import use table at basic prices has no taxes or margins included, so it is already in the correct form for basic flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: Here, import share is computed for each commodity, implying that for each user, the import profile for that good is identical. This is hardly the case in reality, and this tends to overestimate imports in the government and export sectors, and underestimate imports for industries.  StatFin provides detailed data on imports (use table for imports in basic prices). However, since data on taxes and margins are also roughly estimated, using high-detail data on imports causes problems (=negative values) when the basic flows are calculated. Therefore, for consistency, commodity-specific shares are employed. However, if higher quality data on either taxes or margins become available, the use table for imports should be used instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total imports:\n",
    "V0IMP = cleanData[\"supplytable_BP\"].loc[COM][\"P7R_CIF\"]\n",
    "# Commodity specific import share:\n",
    "IMP_SHR = (V0IMP/VPUR_US).fillna(0)\n",
    "# Import share applied to all users:\n",
    "importMatrix = cleanData[\"usetable_PP\"].loc[COM].multiply(IMP_SHR, axis = \"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create margin matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read margins data:\n",
    "MARGIN = cleanData[\"supplytable_BP\"][\"TRTP_MARG\"].copy()\n",
    "# Margin commodities are those with negative values in national accounting:\n",
    "MARGINCOMS = MARGIN[MARGIN<0]\n",
    "MARGIN[MARGIN<0] = 0 \n",
    "\n",
    "# Check that the total use and supply of margin commodities is in balance\n",
    "MARGIN.sum() + MARGINCOMS.sum() < 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the margins dimension as a list:\n",
    "MAR = MARGINCOMS.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inventories are excluded from margin use\n",
    "marginUsers = [y for x in [v for k,v in userNames.items() if k != \"V6\"] for y in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The margin-use-ratios for each commodity are calculated as:\n",
    "\n",
    "$MARUSERATIO(c) =   \\frac{MARGIN(c)}{\\sum{user}\\sum{source} VPUR(u,s,c)}  $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAR_USERATIO = (MARGIN / cleanData[\"usetable_PP\"].loc[COM][marginUsers].sum(axis=1)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, calculate aggregate margin matrices for each user, summed over margin commodity M and source S:\n",
    "MARGIN_DICT1 = {}\n",
    "for i in VPUR_S:\n",
    "    if \"V6PUR\" not in i:\n",
    "        dataName = i\n",
    "        keyName = i[0:2]+\"MAR_S_M\"\n",
    "        MARGIN_DICT1[keyName] = VPUR_S[i].multiply(MAR_USERATIO, axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check balance\n",
    "marTotal1 = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for i in MARGIN_DICT1:\n",
    "    if \"V1\" in i:\n",
    "        marTotal1[\"TOTAL\"] += MARGIN_DICT1[i].sum(axis = 1)\n",
    "    else:\n",
    "        marTotal1[\"TOTAL\"] += MARGIN_DICT1[i].iloc[:,0]\n",
    "\n",
    "marTotal1[\"StatFin\"] = MARGIN\n",
    "cfs.checkCols(marTotal1[\"TOTAL\"], marTotal1[\"StatFin\"], allowDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the aggregate margins are split between different margin commodities:\n",
    "\n",
    "$ MARSHR(m) = \\frac{MARGIN(m)}{\\sum MARGINS(m)}   $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGINS = pd.DataFrame(abs(MARGINCOMS))\n",
    "MARGINS[\"MARSHR\"] = MARGINS[\"TRTP_MARG\"] / float(MARGINS.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGIN_DICT2 = {}\n",
    "for i in MARGIN_DICT1:\n",
    "    dummyFrame  = pd.DataFrame(0.0, index = COM, columns = MARGINS.index)\n",
    "    for j in MARGINS.index:\n",
    "        \n",
    "        if \"V1MAR\" in i:\n",
    "            keyName = i[0:-2]+\"_\"+j\n",
    "            MARGIN_DICT2[keyName] = MARGIN_DICT1[i].multiply(MARGINS[\"MARSHR\"].loc[j])\n",
    "        else:\n",
    "            dummyFrame[j] = MARGIN_DICT1[i] * MARGINS[\"MARSHR\"].loc[j]\n",
    "            MARGIN_DICT2[i[0:-2]] = dummyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# CHECK THAT TOTAL MARGINS EQUAL THE VALUE FROM STATFIN DATABASE\n",
    "marTotal2 = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for i in MARGIN_DICT2:\n",
    "    if \"V1\" in i:\n",
    "        marTotal2[\"TOTAL\"] += MARGIN_DICT2[i].sum(axis = 1)\n",
    "    else:\n",
    "        marTotal2[\"TOTAL\"] += MARGIN_DICT2[i].sum(axis = 1)\n",
    "        \n",
    "marTotal2[\"StatFin\"] = MARGIN\n",
    "cfs.checkCols(marTotal2[\"TOTAL\"], marTotal2[\"StatFin\"], allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors\n"
     ]
    }
   ],
   "source": [
    "# Check that the margin use is correctly distributed between different margin commodities C45- C52\n",
    "marComsDict = {}\n",
    "for k in MARGINCOMS.index:\n",
    "    marComsDict[k] = 0\n",
    "    \n",
    "for i in MARGINCOMS.index:\n",
    "    for j in MARGIN_DICT2:\n",
    "        if \"V1MAR\" in j:\n",
    "            if i in j:\n",
    "                marComsDict[i] += MARGIN_DICT2[j].sum().sum()\n",
    "        else:\n",
    "            marComsDict[i] += MARGIN_DICT2[j][i].sum()\n",
    "\n",
    "errorList = []\n",
    "for com in MARGINCOMS.index:\n",
    "    diff = MARGINCOMS[com] + marComsDict[com]\n",
    "    if abs(diff) > 0.001:\n",
    "        print(\"ERROR IN\", com, \"BY\", diff)\n",
    "        errorList.append([com, diff])\n",
    "if not errorList:\n",
    "    print(\"No errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, split the margins between domestic and imported sources.\n",
    "MARGIN_DICT3 = {}\n",
    "for i in MARGIN_DICT2:\n",
    "    if \"V4\" not in i:\n",
    "        user = i[0:2]\n",
    "        multiplierImp = IMP_SHR\n",
    "        multiplierDom = 1- multiplierImp\n",
    "        newName = i.replace(\"_S\",\"\")\n",
    "\n",
    "        impData = MARGIN_DICT2[i].multiply(multiplierImp, axis = \"index\")\n",
    "        domData = MARGIN_DICT2[i].multiply(multiplierDom, axis = \"index\")\n",
    "\n",
    "        MARGIN_DICT3[newName+\"_imp\"] = impData\n",
    "        MARGIN_DICT3[newName+\"_dom\"] = domData\n",
    "    else:\n",
    "        newName = i.replace(\"_S\",\"\")\n",
    "        MARGIN_DICT3[newName] = MARGIN_DICT2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check margin totals: \n",
    "mar1chk =pd.Series(0.0, index =COM)\n",
    "for k in MARGINCOMS.index:\n",
    "    for s in [\"_dom\", \"_imp\"]:        \n",
    "        mar1chk += MARGIN_DICT3[\"V1MAR_\"+k+s].sum(axis=1)\n",
    "\n",
    "mar2chk =\\\n",
    "MARGIN_DICT3[\"V2MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V2MAR_dom\"].sum(axis=1)\n",
    "\n",
    "mar3chk =\\\n",
    "MARGIN_DICT3[\"V3MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V3MAR_dom\"].sum(axis=1)\n",
    "\n",
    "mar4chk=\\\n",
    "MARGIN_DICT3[\"V4MAR\"].sum(axis=1)\n",
    "\n",
    "mar5chk =\\\n",
    "MARGIN_DICT3[\"V5MAR_imp\"].sum(axis=1)+\\\n",
    "MARGIN_DICT3[\"V5MAR_dom\"].sum(axis=1)\n",
    "\n",
    "summa = sum([mar1chk,mar2chk,mar3chk,mar4chk,mar5chk])\n",
    "cfs.checkCols(summa, MARGIN, allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These aggregate matrixes are used for quick balance checking later on:\n",
    "V1MAR_C = pd.DataFrame(0.0, index = COM, columns = IND)\n",
    "V2MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V3MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V4MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "V5MAR_C = pd.DataFrame(0.0, index = COM, columns = [\"MAR\"])\n",
    "\n",
    "for i in MARGIN_DICT3:\n",
    "    if \"V1MAR\" in i:\n",
    "        data = MARGIN_DICT3[i].sum()     \n",
    "        if \"dom\" in i:\n",
    "            marCom = i[6:].replace(\"_dom\", \"\")\n",
    "        if \"imp\" in i:\n",
    "            marCom = i[6:].replace(\"_imp\", \"\")        \n",
    "        V1MAR_C.loc[marCom] += data\n",
    "  \n",
    "    if \"V2MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V2MAR_C.loc[k] += data.loc[k]\n",
    "\n",
    "\n",
    "    if \"V3MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V3MAR_C.loc[k] += data.loc[k]\n",
    "            \n",
    "    if \"V4MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V4MAR_C.loc[k] += data.loc[k]\n",
    "            \n",
    "    if \"V5MAR\" in i:    \n",
    "        data = MARGIN_DICT3[i].sum() \n",
    "        marComs = MARGIN_DICT3[i].columns\n",
    "        for k in marComs:\n",
    "            V5MAR_C.loc[k] += data.loc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check that margin use matches the supply of margin commodities:\n",
    "cfs.checkNums(V1MAR_C.sum().sum() +\\\n",
    "V2MAR_C.sum() +\\\n",
    "V3MAR_C.sum() +\\\n",
    "V4MAR_C.sum() +\\\n",
    "V5MAR_C.sum(), abs(MARGINCOMS.sum()), allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "VMAR_M={}\n",
    "for user in range(1,6):\n",
    "    VMAR_M[\"V\"+str(user)] = MARGIN_DICT1[\"V\"+str(user)+\"MAR_S_M\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect tax matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXBYCOM  = pd.DataFrame(cleanData[\"supplytable_BP\"][\"D21N\"].copy())\n",
    "\n",
    "# Following Roos et al. (2015), it is supposed that households pay most of the tax burden.\n",
    "# A tax weight factor is therefore assigned, giving households a weight factor of 3, and all other\n",
    "# users a weight factor of 1\n",
    "\n",
    "TAXFAC = pd.DataFrame(1.0, index = userList, columns = [\"TAXFAC\"]).sort_index()\n",
    "TAXFAC.loc[\"P3_S14\"] = 3.0\n",
    "WTOT =   cleanData[\"usetable_PP\"].loc[COM].T.multiply(TAXFAC[\"TAXFAC\"], axis=\"index\").sum()\n",
    "#VPUR_S = cleanData[\"usetable_PP\"].loc[COM][IND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxMatrix = pd.DataFrame(0.0, index = COM, columns = userList)\n",
    "for i in taxMatrix.index:\n",
    "    taxMatrix.loc[i] = TAXFAC[\"TAXFAC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAX = taxMatrix.multiply(TAXBYCOM[\"D21N\"], axis = \"index\")\n",
    "VTAX=(cleanData[\"usetable_PP\"].loc[COM][userList]*TAX).divide(WTOT, axis = \"index\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxDict = {}\n",
    "taxDict[\"V1TAX_S\"] = VTAX[IND]\n",
    "taxDict[\"V2TAX_S\"] = VTAX[\"P51\"]\n",
    "taxDict[\"V3TAX_S\"] = VTAX[\"P3_S14\"]\n",
    "taxDict[\"V4TAX_S\"] = VTAX[\"P6K\"]\n",
    "taxDict[\"V5TAX_S\"] = VTAX[\"P3_S13\"]\n",
    "taxDict[\"V6TAX_S\"] = VTAX[\"P52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "# Check totals:\n",
    "taxTotal = pd.DataFrame(0.0, index = COM, columns = [\"TOTAL\"])\n",
    "for user in taxDict:\n",
    "    if user == \"V1TAX_S\":\n",
    "        taxTotal[\"TOTAL\"] += taxDict[user].sum(axis=1)\n",
    "    else:\n",
    "        taxTotal[\"TOTAL\"] += taxDict[user]\n",
    "cfs.checkCols(TAXBYCOM, taxTotal, allowDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split taxes between domestic and imported:\n",
    "taxDict2 = {}\n",
    "for user in taxDict:\n",
    "    for source in [\"dom\", \"imp\"]:\n",
    "        keyName = user[0:5]+source\n",
    "        origData = taxDict[user]\n",
    "        if source == \"dom\":\n",
    "            newData = origData.multiply(1-IMP_SHR, axis = \"index\")\n",
    "        else:\n",
    "            newData = origData.multiply(IMP_SHR, axis = \"index\")\n",
    "        taxDict2[keyName] = newData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create matrices for basic flows\n",
    "\n",
    "$BAS_{(u,c,dom)} = \\sum_{s \\in SRC}VPUR_{(u,c,s)} - BAS_{(u,c,imp)} - \\sum_{s \\in SRC} \\sum_{m \\in MAR} MAR_{(u,c,s,m)} -  \\sum_{s \\in SRC} TAX_{(u,c,s)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1BASimp = importMatrix[IND]\n",
    "V2BASimp = importMatrix[\"P51\"]\n",
    "V3BASimp = importMatrix[\"P3_S14\"]\n",
    "V4BASimp = importMatrix[\"P6K\"]\n",
    "V5BASimp = importMatrix[\"P3_S13\"]\n",
    "V6BASimp = importMatrix[\"P52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1BASdom = cleanData[\"usetable_PP\"].loc[COM][IND]      - V1BASimp - VMAR_M[\"V1\"] - taxDict[\"V1TAX_S\"]\n",
    "V2BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P51\"]    - V2BASimp - VMAR_M[\"V2\"].iloc[:,0] - taxDict[\"V2TAX_S\"]\n",
    "V3BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P3_S14\"] - V3BASimp - VMAR_M[\"V3\"].iloc[:,0] - taxDict[\"V3TAX_S\"]\n",
    "V4BAS    = cleanData[\"usetable_PP\"].loc[COM][\"P6K\"]    - V4BASimp - VMAR_M[\"V4\"].iloc[:,0] - taxDict[\"V4TAX_S\"]\n",
    "V5BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P3_S13\"] - V5BASimp - VMAR_M[\"V5\"].iloc[:,0] - taxDict[\"V5TAX_S\"]\n",
    "V6BASdom = cleanData[\"usetable_PP\"].loc[COM][\"P52\"]    - V6BASimp - taxDict[\"V6TAX_S\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic flows for V3-V6 have only two dimensions (commodity and source) so they can be compiled to single dataframes:\n",
    "V3BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "V4BAS = V4BAS.to_frame(name = \"V4BAS\")\n",
    "V5BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "V6BAS = pd.DataFrame(0, index=COM, columns=[\"DOM\", \"IMP\"])\n",
    "\n",
    "V3BAS[\"DOM\"] = V3BASdom\n",
    "V3BAS[\"IMP\"] = V3BASimp\n",
    "\n",
    "V5BAS[\"DOM\"] = V5BASdom\n",
    "V5BAS[\"IMP\"] = V5BASimp\n",
    "\n",
    "V6BAS[\"DOM\"] = V6BASdom\n",
    "V6BAS[\"IMP\"] = V6BASimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that no negative values or nan values have emerged:\n",
    "for i in [V1BASdom, pd.DataFrame(V2BASdom), V3BAS, V4BAS, V5BAS]:\n",
    "    cfs.check4negs(i)\n",
    "    cfs.check4nans(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split investments between industries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, industry dimension is added to V2PUR.\n",
    "Industry-specific capital rental share is used as a starting point:\n",
    "\n",
    "IND_SHR(i) = $\\frac{V1CAP(i)}{\\sum V1CAP(i)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_SHR = V1CAP/V1CAP.sum()\n",
    "\n",
    "# Initialize an empty matrix in IND * COM dimension\n",
    "indShareMatrix = pd.DataFrame(0.0, index = COM, columns = IND)\n",
    "\n",
    "# Copy industry share to each row\n",
    "for i in IND:\n",
    "    indShareMatrix[i] = float(IND_SHR.T[i]) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, more detail is added by employing capital formation data from the national accounts, where industry-specific investments are available for different asset groups. The commodity coverage of these assets is limited, but capturing the shares in main investment groups such as buildings and machinery is already a major improvement. In 2014, for instance, buildings and structures accounted for over 55 % of all investments. Machinery and transport equipment accounted for another 20 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gross fixed capital query OK\n"
     ]
    }
   ],
   "source": [
    "# Query the data on gross fixed capital formation:\n",
    "urlDict = {\"Gross fixed capital\": \"kan/vtp/statfin_vtp_pxt_016.px\"}\n",
    "dgf.getData(urlDict, baseYear = baseYear, filters= {\"Tiedot\": [\"CP\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data:\n",
    "capData = {k: pd.read_csv(str(k)+\"_Rawdata.csv\",encoding=\"utf-8\",na_values =\".\") for k in urlDict.keys()} \n",
    "invData = capData[\"Gross fixed capital\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data:\n",
    "for col in invData:\n",
    "    if col in [\"Industry\", \"Sector\", \"Transaction\", \"Asset\", \"Type\"]:\n",
    "        invData[col] = invData[col].apply(lambda x: x.split(\" \")[0]) \n",
    "    if col == \"Industry\":\n",
    "        invData[col] = invData[col].apply(lambda k: \"{}{}\".format(\"I_\", k))\n",
    "invData.drop(\"Information\", axis =1, inplace = True)\n",
    "\n",
    "# ToDo: why are these not automatically in numeric form?\n",
    "invData[str(baseYear)] =invData[str(baseYear)].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Industry names in StatFin input-output data and national accounts do not directly match\n",
    "\n",
    "# Conversion of industry names from national accounts data to IO data.\n",
    "# Please check that these are up-to-date.\n",
    "differences = {\n",
    "\"I_B\": \"I_05_09\",   # Mining and quarrying \n",
    "\"I_F\": \"I_41_43\",   # Construction\n",
    "\"I_I\": \"I_55_56\",   # Accommodation and food service activities\n",
    "\"I_O\": \"I_84\",      # Public administration and social security\n",
    "\"I_681+68209+683\": \"I_68\",  # Real estate activities\n",
    "\"I_68201_68202\":   \"I_68A\"} # Operation of dwellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "invData.replace(differences, inplace = True)\n",
    "invData2 = invData[(invData[\"Industry\"].isin(IND)) & (invData[\"Sector\"] == \"S1\")].reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investment assets and commodities are matched as follows:\n",
    "comAssets = {\n",
    "\"Construction\": [\"C_41_43\"],   # Buildings and structures --> Construction\n",
    "\"Transport\": [\"C_29\", \"C_30\"], # Transport equipment --> Motor vehicles, Other transport equipment\n",
    "\"Machinery\": [\"C_26\", \"C_27\", \"C_28\"]} # ICT equip. and other machinery --> Computer and electronic products, electrical \n",
    "                                                                              # equipment, Other machinery and equipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "invShares = {}\n",
    "invShares[\"Construction\"] = invData2[invData2[\"Asset\"] == \"N111+N112\"].set_index(\"Industry\")[str(baseYear)]\n",
    "invShares[\"Transport\"]    = invData2[invData2[\"Asset\"] == \"N1131\"].set_index(\"Industry\")[str(baseYear)]\n",
    "invShares[\"Machinery\"]    = invData2[invData2[\"Asset\"] == \"N1132+N1139\"].set_index(\"Industry\")[str(baseYear)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in invShares:\n",
    "    invShares[asset][invShares[asset] < 0] = 0\n",
    "    invShares[asset] /= invShares[asset].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the original industry share matrix:\n",
    "for asset in comAssets:\n",
    "    for com in comAssets[asset]:\n",
    "        indShareMatrix.loc[com] = invShares[asset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last, split data using the new shares:\n",
    "V2BASdom = indShareMatrix.multiply(V2BASdom, axis = \"index\")\n",
    "V2BASimp = indShareMatrix.multiply(V2BASimp, axis = \"index\")\n",
    "\n",
    "taxDict2[\"V2TAXdom\"] = indShareMatrix.multiply(taxDict2[\"V2TAXdom\"], axis =\"index\")\n",
    "taxDict2[\"V2TAXimp\"] = indShareMatrix.multiply(taxDict2[\"V2TAXimp\"], axis =\"index\")\n",
    "\n",
    "VPUR_S[\"V2PUR\"] = indShareMatrix.multiply(VPUR_S[\"V2PUR\"][\"P51\"], axis = \"index\")\n",
    "\n",
    "for k in MARGINCOMS.index:\n",
    "    for s in [\"dom\", \"imp\"]:\n",
    "        MARGIN_DICT3[\"V2MAR_\"+k+\"_\"+s] = indShareMatrix.multiply(MARGIN_DICT3[\"V2MAR_\"+s][k], axis = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant aggregates\n",
    "for key in ['V2MAR_imp', 'V2MAR_dom']:\n",
    "    try:\n",
    "        del MARGIN_DICT3[key]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Check balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIFFIND is COSTS-MAKE_C : should be zero\n",
    "allowDifference = 0.005\n",
    "DIFFIND = pd.DataFrame(0.0, index = IND, columns = [\"COSTS\", \"MAKE_C\", \"DIFFERENCE\"])\n",
    "\n",
    "#Value ad\n",
    "DIFFIND[\"COSTS\"] += V1LAB_O\n",
    "DIFFIND[\"COSTS\"] += V1CAP[\"V1CAP\"]\n",
    "DIFFIND[\"COSTS\"] += V1LND[\"V1LND\"]\n",
    "DIFFIND[\"COSTS\"] += V1PTX[\"D29MD39\"]\n",
    "DIFFIND[\"COSTS\"] += V1OCT[\"V1OCT\"]\n",
    "\n",
    "DIFFIND[\"COSTS\"] += V1BASdom.sum()\n",
    "DIFFIND[\"COSTS\"] += importMatrix[IND].sum()\n",
    "DIFFIND[\"COSTS\"] += taxDict[\"V1TAX_S\"].sum()\n",
    "DIFFIND[\"COSTS\"] += VMAR_M[\"V1\"].sum()\n",
    "\n",
    "DIFFIND[\"MAKE_C\"] += MAKE.sum()\n",
    "\n",
    "DIFFIND[\"DIFFERENCE\"] = DIFFIND[\"COSTS\"] - DIFFIND[\"MAKE_C\"]\n",
    "difData1 = DIFFIND[abs(DIFFIND[\"DIFFERENCE\"]) > allowDifference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For I_28 V1CAP is adjusted by -0.005999999997584382\n",
      "For I_31_32 V1CAP is adjusted by -0.005000000000109139\n",
      "For I_61 V1CAP is adjusted by 0.005000000000109139\n"
     ]
    }
   ],
   "source": [
    "# If there is a difference, transfer it into V1CAP\n",
    "for ind in difData1.index:\n",
    "    value = difData1.loc[ind][\"DIFFERENCE\"]\n",
    "    print(\"For\", ind, \"V1CAP is adjusted by\", value)\n",
    "    V1CAP.loc[ind] -= value\n",
    "if difData1.empty:\n",
    "    print(\"No errors, no adjustments made\")\n",
    "cfs.check4negs(V1CAP, printOK = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARGSALES = pd.DataFrame(0.0, index = COM, columns = [\"MARGSALES\"])\n",
    "for i in MARGINCOMS.index:\n",
    "    MARGSALES[\"MARGSALES\"][i] = abs(MARGINCOMS[i])\n",
    "\n",
    "# DIFFCOM is COM_OUTPUT - COM_USE : should be zero\n",
    "DIFFCOM = pd.DataFrame(0.0, index = COM, columns = [\"OUTPUT\", \"USE\", \"DIFFERENCE\"])\n",
    "\n",
    "DIFFCOM[\"OUTPUT\"] += MAKE.sum(axis=1)\n",
    "\n",
    "DIFFCOM[\"USE\"] += V1BASdom.sum(axis = 1)\n",
    "DIFFCOM[\"USE\"] += V2BASdom.sum(axis = 1)\n",
    "DIFFCOM[\"USE\"] += V3BASdom\n",
    "DIFFCOM[\"USE\"] += V4BAS[\"V4BAS\"]\n",
    "DIFFCOM[\"USE\"] += V5BASdom\n",
    "DIFFCOM[\"USE\"] += V6BASdom\n",
    "DIFFCOM[\"USE\"] += MARGSALES[\"MARGSALES\"]\n",
    "\n",
    "DIFFCOM[\"DIFFERENCE\"] = DIFFCOM[\"OUTPUT\"] - DIFFCOM[\"USE\"]\n",
    "\n",
    "difData2 = DIFFCOM[abs(DIFFCOM[\"DIFFERENCE\"]) > allowDifference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C_37_39 V6BAS is adjusted by 0.005000000000109139\n",
      "For C_49 V6BAS is adjusted by 0.0059999999994033715\n",
      "For C_77 V6BAS is adjusted by 0.006999999998697604\n"
     ]
    }
   ],
   "source": [
    "for com in difData2.index:\n",
    "    value = difData2.loc[com][\"DIFFERENCE\"]\n",
    "    print(\"For\", com, \"V6BAS is adjusted by\", value)\n",
    "    V6BASdom.loc[com] +=  value\n",
    "if difData2.empty:\n",
    "    print(\"No errors, no adjustments made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some parameters and coefficients for model homogenity testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramSheets =[sheet for sheet in pd.read_excel(\"supplementaryData/PARAMETERS64.xlsx\", sheet_name=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramDict = {}\n",
    "for sheet in paramSheets:\n",
    "    paramDict[sheet] = pd.read_excel(\"supplementaryData/PARAMETERS64.xlsx\", sheet_name = sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramNames = {\n",
    "\"1ARM\": \"Intermediate Armington\",\n",
    "\"2ARM\": \"Investment Armington\",\n",
    "\"3ARM\": \"Households Armington\",\n",
    "\"ITEX\": \"Flag, >0.5 for individual export coms, else collective export\",\n",
    "\"LCOM\": \"Flag for regional extension, >0.5 for local coms, else national\",\n",
    "\"LIND\": \"Local industries\",\n",
    "\"P018\": \"Traditional Export Elasticities\",\n",
    "\"P028\": \"Primary Factor Sigma\",\n",
    "\"SCET\": \"Output Sigma\",\n",
    "\"SLAB\": \"Labour Sigma\",\n",
    "\"XPEL\": \"Household Expenditure Elasticities\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data as numpy arrays before exporting them as HAR files\n",
    "V1BAS = np.stack((V1BASdom.values, V1BASimp.values), axis=1)\n",
    "V2BAS = np.stack((V2BASdom.values, V2BASimp.values), axis=1)\n",
    "\n",
    "V1TAX = np.stack((taxDict2[\"V1TAXdom\"].values, taxDict2[\"V1TAXimp\"].values), axis = 1)\n",
    "V2TAX = np.stack((taxDict2[\"V2TAXdom\"].values, taxDict2[\"V2TAXimp\"].values), axis = 1)\n",
    "V3TAX = pd.concat([taxDict2[\"V3TAXdom\"],taxDict2[\"V3TAXimp\"]], axis = 1)\n",
    "V4TAX = taxDict[\"V4TAX_S\"]\n",
    "V5TAX = np.stack((taxDict2[\"V5TAXdom\"].values, taxDict2[\"V5TAXimp\"].values), axis = 1)\n",
    "V6TAX = np.stack((taxDict2[\"V6TAXdom\"].values, taxDict2[\"V6TAXimp\"].values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note dstack = along the 3rd dimension for margins!\n",
    "V1MAR = np.stack([\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V1MAR\" in key and \"dom\" in key]),\\\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V1MAR\" in key and \"imp\" in key])], axis=1)\n",
    "\n",
    "V2MAR = np.stack([\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V2MAR\" in key and \"dom\" in key]),\\\n",
    "np.dstack([MARGIN_DICT3[key].values for key in MARGIN_DICT3.keys() if \"V2MAR\" in key and \"imp\" in key])], axis=1)\n",
    "\n",
    "V3MAR = np.stack((MARGIN_DICT3[\"V3MAR_dom\"].values, MARGIN_DICT3[\"V3MAR_imp\"].values), axis = 1)\n",
    "V4MAR = MARGIN_DICT3[\"V4MAR\"]\n",
    "V5MAR = np.stack((MARGIN_DICT3[\"V5MAR_dom\"].values, MARGIN_DICT3[\"V5MAR_imp\"].values), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDims = {\n",
    "\"COM\": COM,            # Commodities\n",
    "\"IND\": IND,            # Industries\n",
    "\"OCC\": OCC,            # Occupations\n",
    "\"SRC\": [\"DOM\", \"IMP\"], # Sources\n",
    "\"MAR\": MAR}            # Margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseData={\n",
    "#coefficient name: (dataset, header name, long name, [list of dimensions])\n",
    "\"V1CAP\": (V1CAP, \"1CAP\", \"Capital rentals\", [\"IND\"]),\n",
    "\"V1LND\": (V1LND, \"1LND\", \"Land rentals\", [\"IND\"]),\n",
    "\"V1LAB\": (V1LAB, \"1LAB\", \"Labor compensation\", [\"IND\", \"OCC\"]),\n",
    "\"MAKE\":  (MAKE,  \"MAKE\", \"Multi-production matrix\", [\"COM\", \"IND\"]),\n",
    "\"V1PTX\": (V1PTX, \"1PTX\", \"Production tax\", [\"IND\"]),\n",
    "\"V0TAR\": (V0TAR, \"0TAR\", \"Tariff revenue\", [\"COM\"]),\n",
    "\"V1OCT\": (V1OCT, \"1OCT\", \"Other cost ticket\", [\"IND\"]),\n",
    "# Basic flows    \n",
    "\"V1BAS\": (V1BAS, \"1BAS\", \"Intermediate basic\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V2BAS\": (V2BAS, \"2BAS\", \"Investment basic\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V3BAS\": (V3BAS, \"3BAS\", \"Household basic\", [\"COM\", \"SRC\"]),\n",
    "\"V4BAS\": (V4BAS, \"4BAS\", \"Export basic\", [\"COM\"]),\n",
    "\"V5BAS\": (V5BAS, \"5BAS\", \"Government basic\", [\"COM\", \"SRC\"]),\n",
    "\"V6BAS\": (V6BAS, \"6BAS\", \"Inventories basic\", [\"COM\", \"SRC\"]),\n",
    "# Basic taxes    \n",
    "\"V1TAX\": (V1TAX, \"1TAX\", \"Intermediate tax\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V2TAX\": (V2TAX, \"2TAX\", \"Investment tax\", [\"COM\", \"SRC\", \"IND\"]),\n",
    "\"V3TAX\": (V3TAX, \"3TAX\", \"Household tax\", [\"COM\", \"SRC\"]),\n",
    "\"V4TAX\": (V4TAX, \"4TAX\", \"Export tax\", [\"COM\"]),\n",
    "\"V5TAX\": (V5TAX, \"5TAX\", \"Government tax\", [\"COM\", \"SRC\"]),\n",
    "\"V6TAX\": (V6TAX, \"6TAX\", \"Inventories tax\", [\"COM\", \"SRC\"]),\n",
    "# Margins\n",
    "\"V1MAR\": (V1MAR, \"1MAR\", \"Intermediate margins\", [\"COM\", \"SRC\", \"IND\", \"MAR\"]),\n",
    "\"V2MAR\": (V2MAR, \"2MAR\", \"Investment margins\", [\"COM\", \"SRC\", \"IND\", \"MAR\"]),\n",
    "\"V3MAR\": (V3MAR, \"3MAR\", \"Household margins\", [\"COM\", \"SRC\", \"MAR\"]),\n",
    "\"V4MAR\": (V4MAR, \"4MAR\", \"Export margins\", [\"COM\", \"MAR\"]),\n",
    "\"V5MAR\": (V5MAR, \"5MAR\", \"Government margins\", [\"COM\", \"SRC\", \"MAR\"]),\n",
    "# Constants\n",
    "\"EXP_ELAST\": (2.0, \"EXNT\", \"Collective export elasticity\", []),\n",
    "\"FRISCH\": (1.5, \"P021\", \"Frisch parameter\", []),\n",
    "\"BASEYEAR\": (baseYear, \"BYER\", \"Data base year\", [])\n",
    "}\n",
    "\n",
    "# Necessary params for homogenity test:\n",
    "for param in paramDict:\n",
    "    if all(paramDict[param].index == COM):\n",
    "        dimension = [\"COM\"]\n",
    "    elif all(paramDict[param].index == IND):\n",
    "        dimension = [\"IND\"]\n",
    "    else:\n",
    "        raise ValueError(\"Check the index for\", param)\n",
    "        \n",
    "    coeffName = paramDict[param].columns[0]\n",
    "    baseData[param] = (paramDict[param], param, paramNames[param], dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dimensions as sets. Also include the regional data:\n",
    "output = {**allDims, **baseData}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwf.data2har(output, allDims).writeToDisk(\"baseData\"+str(baseYear)+\".har\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating AGGSUP.har supplementary file for aggregating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data used for weighted aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1PRIM = V1LAB_O + V1CAP[\"V1CAP\"] + V1LND[\"V1LND\"]\n",
    "V1MAT = VPUR_S[\"V1PUR\"].sum()\n",
    "V1CST = V1PRIM + V1OCT[\"V1OCT\"] + V1MAT\n",
    "V1TOT = V1CST + V1PTX[\"D29MD39\"]\n",
    "V2TOT = VPUR_S[\"V2PUR\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1PUR_SI = VPUR_S[\"V1PUR\"].sum(axis=1)\n",
    "V2PUR_SI = VPUR_S[\"V2PUR\"].sum(axis=1)\n",
    "V3PUR_S  = VPUR_S[\"V3PUR\"][\"P3_S14\"]\n",
    "V4PUR    = VPUR_S[\"V4PUR\"][\"P6K\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mappings for direct aggregation\n",
    "\n",
    "Commodities and Industries are mapped to match the level at which regional data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dgf.searchStatfin(\"Output by region 30 industries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "regIndRaw = [x[\"values\"] for x in dgf.getParams(\"statfin_altp_pxt_008.px\") if x[\"code\"] == \"Toimiala\"][0]\n",
    "#regIndRaw = ['0', '01', '02_03', '05_09', '10_12', '13_15', '16', '17_18', '19_22', '23', '24_25', '26_27', \n",
    "#          '28', '29_30', '31_33','35_39', '41_43', '45_47', '49_53', '55_56', '58_63', '64_66', '681+68209+683', \n",
    "#          '68201_68202', '69_75', '77_82', '84', '85', '86_88', '90_96', '97_98']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "renameInd = {           # From regional accounts naming convention to input-output convention\n",
    "\"681+68209+683\": \"68\",  # Other real estate activities  --> Real estate activities\n",
    "\"68201_68202\"  : \"68A\"} # Letting and operation of dwellings  --> Operation of dwellings and residential real estate\n",
    "\n",
    "regInd = [renameInd.get(n, n) for n in regIndRaw if n != \"0\"] # Rename and drop \"0\" (Industries total)\n",
    "\n",
    "# Last, add the prefix \"I_\" to all regional industries:\n",
    "regInd = [\"I_\"+i for i in regInd]\n",
    "regCom = [\"C_\" + c[2:] for c in regInd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from IND to regInd and COM to regCom\n",
    "MIND = mf.mapperFunction(IND, regInd)\n",
    "MCOM = mf.mapperFunction(COM, regCom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggSup={\n",
    "#coefficient name: (dataset, header name, long name, [list of dimensions])\n",
    "\"V1TOT\":  (V1TOT, \"1TOT\", \"Industry output\", [\"IND\"]),\n",
    "\"V2TOT\":  (V2TOT, \"2TOT\", \"Investment by industry\", [\"IND\"]),\n",
    "\"V1PRIM\": (V1PRIM, \"VLAD\", \"Total factor input to industry\", [\"IND\"]),\n",
    "\"V1LAB_O\":(V1LAB_O, \"1LAB\", \"Industry wages\", [\"IND\"]),\n",
    "\"V1PUR\":  (V1PUR_SI, \"1PUR\", \"Intermediate use at purch. price\", [\"COM\"]),\n",
    "\"V2PUR\":  (V2PUR_SI, \"2PUR\", \"Investment use at purch. price\", [\"COM\"]),\n",
    "\"V3PUR\":  (V3PUR_S, \"3PUR\", \"Consumption at purch. price\", [\"COM\"]),\n",
    "\"V4PUR\":  (V4PUR, \"4PUR\", \"Export at purch. price\", [\"COM\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAGG = [\n",
    "# Headers that are used in weighted aggregations for elasticities and ratios\n",
    "\"1ARM 1PUR\",\n",
    "\"2ARM 2PUR\",\n",
    "\"3ARM 3PUR\",\n",
    "\"XPEL 3PUR\",\n",
    "\"P018 4PUR\",\n",
    "\"P028 VLAD\",\n",
    "\"SLAB 1LAB\",\n",
    "\"SCET 1TOT\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggDims = {\n",
    "\"COM\":  COM,     # All commodities \n",
    "\"IND\":  IND,     # All industries\n",
    "\"ACOM\": regCom,  # Regional commodities\n",
    "\"AIND\": regInd,  # Regional industries\n",
    "\"WAGG\": WAGG,    # Headers for weighted aggregation\n",
    "#\"MCOM\": [str(c) for c in MCOM.values()],\n",
    "#\"MIND\": [str(i) for i in MIND.values()]\n",
    "}\n",
    "\n",
    "# At the moment, mappings must be specified using the HAR program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {**aggDims, **aggSup}\n",
    "hwf.data2har(output, aggDims).writeToDisk(\"AGGSUP\"+str(baseYear)+\".har\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PROGRAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
